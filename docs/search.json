[
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Health Economics II",
    "section": "Instructor",
    "text": "Instructor\n Ian McCarthy  R. Rollins, R418  ian.mccarthy@emory.edu  @ianhealthecon  Schedule an appointment"
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Health Economics II",
    "section": "Course Details",
    "text": "Course Details\n 1-13-2026 to 4-23-2026  Tuesday, Thursday  10:00am to 11:15am T/Th  Ignatius Few 129"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course explores the industrial organization of healthcare markets in the U.S., sometimes referred to as supply-side health economics or the economics of healthcare (to differentiate from the economics of health). We will focus on the following areas: health insurance, physician agency, healthcare pricing and competition, information disclosure, physician learning, and physician labor markets. As we cover some of the key papers in these areas, we will discuss and employ tools from the fields of empirical IO and causal inference. These methods will be discuseed as needed throughout the course, but students are expected to have a working knowledge of these methods prior to the start of the course."
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "",
    "text": "This course explores the industrial organization of healthcare markets in the U.S., sometimes referred to as supply-side health economics or the economics of healthcare (to differentiate from the economics of health). We will focus on the following areas: health insurance, physician agency, healthcare pricing and competition, information disclosure, physician learning, and physician labor markets. As we cover some of the key papers in these areas, we will discuss and employ tools from the fields of empirical IO and causal inference. These methods will be discuseed as needed throughout the course, but students are expected to have a working knowledge of these methods prior to the start of the course."
  },
  {
    "objectID": "syllabus.html#learning-outcomes",
    "href": "syllabus.html#learning-outcomes",
    "title": "Syllabus",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nI have four central goals for this course:\n\nSynthesize the current literature in each of the main areas of health economics covered in this class\nApply standard causal inference techniques in the area of healthcare\nCritically evaluate key papers in the field, identifying core strengths of the research\nDevelop your own preliminary research in some area of healthcare economics\n\nOur class times and your presentations are designed to help achieve the first goal; the second and third goals align with our homework assignments; and the final goal is achieved through the research proposals and research plan. The assignments are described in more detail on the class assignments page."
  },
  {
    "objectID": "syllabus.html#text-software-and-class-materials",
    "href": "syllabus.html#text-software-and-class-materials",
    "title": "Syllabus",
    "section": "Text, Software, and Class Materials",
    "text": "Text, Software, and Class Materials\n\nReadings: As an elective PhD course, we will rely on academic papers from the reading list in each module. I expect everyone to read the papers in advance and come to class with questions on the study’s contribution, empirical techniques, identification strategies, and datasets used. My goal with each paper is to discuss the analysis in as much detail as possible within our time constraints. As such, we’ll focus on relatively fewer papers in class. I’ve provided a more comprehensive reading list in each module for those interested in additional readings in a specific area.\nSoftware: For anything data related, I’ll use R, but you are free to use whatever software you’re most comfortable with in your empirical work. I encourage you to use R, Stata, or Python simply because these are the most common programs used in practice right now. You’ll also need to have a basic working knowledge of Git and GitHub. If you’re new to these tools, take a look at Grant McDermott’s notes on Data Science for Economists as well as Jenny Bryan’s online reference book, Happy Git and GitHub with R.\nSlides and Notes: Any presentations will be made available on our class website prior to any given class."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\nVarious policies for this course are described below. Basically, let’s all work to be good citizens and take seriously our various roles as a student, teacher, friend, colleague, human, etc.\n\nAcademic integrity\nThe Emory University Honor Code is taken seriously and governs all work in this course. Details about the Honor Code are available in the Laney Graduate School Handbook and available online here. By taking this course, you affirm that it is a violation of the code to plagiarize, to deviate from the instructions about collaboration on work that is submitted for grades, to give false information to a faculty member, and to undertake any other form of academic misconduct. You also affirm that if you witness others violating the code you have a duty to report them to the honor council.\n\n\nAccessibility services\nIf you anticipate issues related to the format or requirements of this course, please meet with me. I would like us to discuss ways to ensure your full participation in the course. If you determine that accommodations are necessary, you may register with Accessibility Services at (404)727-9877 or via e-mail at accessibility@emory.edu. To register with OAS, students must self identify and initiate contact with the OAS office.\n\n\nCommunication\nI will post regular announcements to the class on Canvas, so please set up your notifications on Canvas accordingly. I will also use Canvas to post all grades and any other information that needs to stay in the class (like our Zoom meeting link for virtual meetings, if needed). All other course materials will be available on our class website, econ771s26.classes.ianmccarthyecon.com/.\nPlease feel free to reach out to me for any reason. I generally respond to all e-mails within 24 hours.\n\n\nOffice Hours\nMy designated office hours are 1:00-2:30pm on Tuesday and Thursday in R418 of the R. Randall Rollins building. I’m happy to meet outside of normal office hours as well. Please feel free to schedule another time to meet by following the link to select a time that works for you, https://mccarthy-meetings.youcanbook.me. Unless otherwise noted, all meetings will be held in my office. If you need to meet virtually, please let me know and I’ll send you a Zoom link.\n\n\nAttendance\nWhile there is no official “attendance” credit, everyone is expected to attend all class sessions. Given our small class, it is very important that we are all present and engaged."
  },
  {
    "objectID": "syllabus.html#assignments-and-grading",
    "href": "syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThere are four main assignments throughout the semester. I describe each assignment below, with more detail provided on our assignments page.\n\nResearch Proposals and Final Plans\nYou will submit three research proposals throughout the semester. These are short, 1-2 page documents that outline a problem/motivation, a related research question, potential data to help answer this question, and a proposed empirical strategy. The goal of these proposals is to help you develop your own research ideas and to get feedback from me and your classmates.\nToward the end of the semester, I will meet with each of you (one-on-one) to discuss your proposals. Based on that feedback, you will develop one of these proposals into a more complete research plan. Details of the research proposal and plans are available on the assignments page of our class website.\n\n\nPresentations\nYou will present four papers throughout the course of the semester. Please note your selected papers and class dates on the Presentations tab of our shared Google Sheet no later than Friday, January 16. If you do not select papers by then, I’ll have to assign papers unilaterally. The list of potential papers to present and details of the expectations for each presentation are available on the assignments page of our class website.\n\n\nEmpirical Exercises\nThere is an applied component of this course where we spend some time with a real-life causal inference question. These will require some of your time outside of class to get the data in working order and implement the relevant identification strategy and econometric estimator. Raw data for each exercise will be provided on our class OneDrive notebook, the link to which is on Canvas, or simply through the paper’s replication package online. There are four possible empirical exercises, from which you must choose one. Please note your selections no later than Thursday, January 29.\n\n\nImportant Deadlines\nThis section is just to highlight important dates for assignments throughout the semester. Note that late assignments will receive an automatic 5% reduction in the grade for each day the assignment is turned in after the due date.\n\nSelect Papers to Present no later than January 16: Note the papers you plan to present on the Presentations tab of our shared Google Sheet (link available on Canvas). Only one student per paper, so this is first-come first-served. Remember you need to select four papers to present throughout the semester. Please spread these presentations out over the semester.\nSelect Empirical Exercise no later than January 29: Note your selection on the Exercises tab of our shared Google Sheet. No more than two students per exercise.\nThe first Research Proposal is due on February 5\nThe second Research Proposal is due on February 26\nThe Excellence Blueprint is due on March 17\nThe third Research Proposal is due on March 26\nFinal Research Plans are due on April 21 and will be presented in class on April 21 and April 23\n\nEmpirical Exercises are due on April 23"
  },
  {
    "objectID": "syllabus.html#final-grades",
    "href": "syllabus.html#final-grades",
    "title": "Syllabus",
    "section": "Final grades",
    "text": "Final grades\n\n40% for research proposals (10% for each proposal and 10% for the research plan)\n20% for empirical exercises\n20% for excellence blueprint\n20% for presentations of selected papers (5% each)\n\nLetter grades will be assigned at the end of the course based on total score achieved: (A = 100-93%, A- = 92.99-90%, B+ = 89.99-87%, B = 86.99-83%, B- = 82.99-80%, C+ = 79.99-77%, C = 76.99-73%, C- = 72.99-70%, D+ = 69.99-67%, D = 66.99-60%, F = 60% or less)"
  },
  {
    "objectID": "slides/class9.html",
    "href": "slides/class9.html",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "",
    "text": "Panel Data and Fixed Effects\nDifference-in-Differences Yesterday\nDifference-in-Differences Today\nBrief Notes on Empirical Exercise"
  },
  {
    "objectID": "slides/class9.html#outline",
    "href": "slides/class9.html#outline",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "",
    "text": "Panel Data and Fixed Effects\nDifference-in-Differences Yesterday\nDifference-in-Differences Today\nBrief Notes on Empirical Exercise"
  },
  {
    "objectID": "slides/class9.html#basics-of-panel-data",
    "href": "slides/class9.html#basics-of-panel-data",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Basics of panel data",
    "text": "Basics of panel data\n\nRepeated observations of the same units over time (balanced vs unbalanced)\nIdentification due to variation within unit\n\n\nNotation\n\nUnit \\(i=1,...,N\\) over several periods \\(t=1,...,T\\), which we denote \\(y_{it}\\)\nTreatment status \\(D_{it}\\)\nRegression model,  \\(y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}\\) for \\(t=1,...,T\\) and \\(i=1,...,N\\)"
  },
  {
    "objectID": "slides/class9.html#benefits-of-panel-data",
    "href": "slides/class9.html#benefits-of-panel-data",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Benefits of Panel Data",
    "text": "Benefits of Panel Data\n\nMay overcome certain forms of omitted variable bias\nAllows for unobserved but time-invariant factor, \\(\\gamma_{i}\\), that affects both treatment and outcomes\n\n\nStill assumes\n\nNo time-varying confounders\nPast outcomes do not directly affect current outcomes\nPast outcomes do not affect treatment (reverse causality)"
  },
  {
    "objectID": "slides/class9.html#some-textbook-settings",
    "href": "slides/class9.html#some-textbook-settings",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Some textbook settings",
    "text": "Some textbook settings\n\nUnobserved “ability” when studying schooling and wages\nUnobserved “quality” when studying physicians or hospitals"
  },
  {
    "objectID": "slides/class9.html#fixed-effects-and-regression",
    "href": "slides/class9.html#fixed-effects-and-regression",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Fixed effects and regression",
    "text": "Fixed effects and regression\n\\(y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}\\) for \\(t=1,...,T\\) and \\(i=1,...,N\\)\n\n\nAllows correlation between \\(\\gamma_{i}\\) and \\(D_{it}\\)\nPhysically estimate \\(\\gamma_{i}\\) in some cases via set of dummy variables\nMore generally, “remove” \\(\\gamma_{i}\\) via:\n\n“within” estimator\nfirst-difference estimator"
  },
  {
    "objectID": "slides/class9.html#within-estimator",
    "href": "slides/class9.html#within-estimator",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Within Estimator",
    "text": "Within Estimator\n\\(y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}\\) for \\(t=1,...,T\\) and \\(i=1,...,N\\)\n\n\nMost common approach (default in most statistical software)\nEquivalent to demeaned model: \\[y_{it} - \\bar{y}_{i} = \\delta (D_{it} - \\bar{D}_{i}) + (\\gamma_{i} - \\bar{\\gamma}_{i}) + (\\gamma_{t} - \\bar{\\gamma}_{t}) + (\\epsilon_{it} - \\bar{\\epsilon}_{i})\\]\n\\(\\gamma_{i} - \\bar{\\gamma}_{i} = 0\\) since \\(\\gamma_{i}\\) is time-invariant\nRequires strict exogeneity assumption (error is uncorrelated with \\(D_{it}\\) for all time periods)"
  },
  {
    "objectID": "slides/class9.html#first-difference",
    "href": "slides/class9.html#first-difference",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "First-difference",
    "text": "First-difference\n\\(y_{it} = \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\epsilon_{it}\\) for \\(t=1,...,T\\) and \\(i=1,...,N\\)\n\n\nInstead of subtracting the mean, subtract the prior period values \\[y_{it} - y_{i,t-1} = \\delta(D_{it} - D_{i,t-1}) + (\\gamma_{i} - \\gamma_{i}) + (\\gamma_{t} - \\gamma_{t-1}) + (\\epsilon_{it} - \\epsilon_{i,t-1})\\]\nRequires exogeneity of \\(\\epsilon_{it}\\) and \\(D_{it}\\) only for time \\(t\\) and \\(t-1\\) (weaker assumption than within estimator)\nSometimes useful to estimate both FE and FD just as a check"
  },
  {
    "objectID": "slides/class9.html#keep-in-mind",
    "href": "slides/class9.html#keep-in-mind",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Keep in mind…",
    "text": "Keep in mind…\n\nDiscussion only applies to linear case or very specific nonlinear models\nFixed effects at lower “levels” accommodate fixed effects at higher levels (e.g., FEs for hospital combine to form FEs for zip code, etc.)\nFixed effects can’t solve reverse causality\nFixed effects don’t address unobserved, time-varying confounders\nCan’t estimate effects on time-invariant variables\nMay “absorb” a lot of the variation for variables that don’t change much over time"
  },
  {
    "objectID": "slides/class9.html#within-estimator-default-in-practice",
    "href": "slides/class9.html#within-estimator-default-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Within Estimator (Default) in practice",
    "text": "Within Estimator (Default) in practice\n\n\nStata\n\nssc install causaldata\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\ntsset country year\nxtreg lifeExp lgdp_pc, fe\n\n\nR\n\nlibrary(fixest)\nlibrary(causaldata)\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap))\nfeols(lifeExp~lgdp_pc | country, data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#within-estimator-default-in-practice-1",
    "href": "slides/class9.html#within-estimator-default-in-practice-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Within Estimator (Default) in practice",
    "text": "Within Estimator (Default) in practice\n\n\nR Code\nlibrary(fixest)\nlibrary(modelsummary)\nlibrary(causaldata)\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap))\nm1 &lt;- feols(lifeExp ~ lgdp_pc | country, data=reg.dat)\nmodelsummary(list(\"Default FE\"=m1), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Default FE\n              \n        \n        \n        \n                \n                  Log GDP per Capita\n                  9.769  \n                \n                \n                                    \n                  (0.702)"
  },
  {
    "objectID": "slides/class9.html#within-estimator-manually-demean-in-practice",
    "href": "slides/class9.html#within-estimator-manually-demean-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Within Estimator (Manually Demean) in practice",
    "text": "Within Estimator (Manually Demean) in practice\n\n\nStata\n\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\nforeach x of varlist lifeExp lgdp_pc {\n  egen mean_`x'=mean(`x')\n  egen demean_`x'=`x'-mean_`x'\n}\nreg demean_lifeExp demean_lgdp_pc\n\n\nR\n\nlibrary(causaldata)\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap)) %&gt;%\n  group_by(country) %&gt;%\n  mutate(demean_lifeexp=lifeExp - mean(lifeExp, na.rm=TRUE),\n         demean_gdp=lgdp_pc - mean(lgdp_pc, na.rm=TRUE))\nlm(demean_lifeexp~ 0 + demean_gdp, data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#within-estimator-manually-demean-in-practice-1",
    "href": "slides/class9.html#within-estimator-manually-demean-in-practice-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Within Estimator (Manually Demean) in practice",
    "text": "Within Estimator (Manually Demean) in practice\n\n\nR Code\nlibrary(lmtest)\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  group_by(country) %&gt;%\n  mutate(lgdp_pc=log(gdpPercap),\n         lgdp_pc=lgdp_pc - mean(lgdp_pc, na.rm=TRUE),\n         lifeExp=lifeExp - mean(lifeExp, na.rm=TRUE))\n\nm2 &lt;- lm(lifeExp~ 0 + lgdp_pc , data=reg.dat)\nmodelsummary(list(\"Default FE\"=m1, \"Manual FE\"=m2), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"),\n             vcov = ~country)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Default FE\n                Manual FE\n              \n        \n        \n        \n                \n                  Log GDP per Capita\n                  9.769  \n                  9.769  \n                \n                \n                                    \n                  (0.702)\n                  (0.701)\n                \n        \n      \n    \n\n\n\nNote: feols defaults to clustering at level of FE, lm requires our input"
  },
  {
    "objectID": "slides/class9.html#first-differencing-default-in-practice",
    "href": "slides/class9.html#first-differencing-default-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "First differencing (default) in practice",
    "text": "First differencing (default) in practice\n\n\nStata\n\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\nreg d.lifeExp d.lgdp_pc, noconstant\n\n\nR\n\nlibrary(plm)\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap))\n\nplm(lifeExp ~ 0 + lgdp_pc, model=\"fd\", individual=\"country\", index=c(\"country\",\"year\"), data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#first-differencing-manual-in-practice",
    "href": "slides/class9.html#first-differencing-manual-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "First differencing (manual) in practice",
    "text": "First differencing (manual) in practice\n\n\nR Code\nlibrary(plm)\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap))\n\nm3 &lt;- plm(lifeExp ~ 0 + lgdp_pc, model=\"fd\", index=c(\"country\",\"year\"), data=reg.dat)\n\nmodelsummary(list(\"Default FE\"=m1, \"Manual FE\"=m2, \"Default FD\"=m3), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Default FE\n                Manual FE\n                Default FD\n              \n        \n        \n        \n                \n                  Log GDP per Capita\n                  9.769  \n                  9.769  \n                  5.290  \n                \n                \n                                    \n                  (0.702)\n                  (0.284)\n                  (0.291)"
  },
  {
    "objectID": "slides/class9.html#first-differencing-manual-in-practice-1",
    "href": "slides/class9.html#first-differencing-manual-in-practice-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "First differencing (manual) in practice",
    "text": "First differencing (manual) in practice\n\n\nStata\n\ncausaldata gapminder.dta, use clear download\ngen lgdp_pc=log(gdppercap)\nreg d.lifeExp d.lgdp_pc, noconstant\n\n\nR\n\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap)) %&gt;%  \n  group_by(country) %&gt;%\n  arrange(country, year) %&gt;%\n  mutate(fd_lifeexp=lifeExp - lag(lifeExp),\n         lgdp_pc=lgdp_pc - lag(lgdp_pc)) %&gt;%\n  na.omit()\n\nlm(fd_lifeexp~ 0 + lgdp_pc , data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#first-differencing-manual-in-practice-2",
    "href": "slides/class9.html#first-differencing-manual-in-practice-2",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "First differencing (manual) in practice",
    "text": "First differencing (manual) in practice\n\n\nR Code\nreg.dat &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap)) %&gt;%  \n  group_by(country) %&gt;%\n  arrange(country, year) %&gt;%  \n  mutate(fd_lifeexp=lifeExp - dplyr::lag(lifeExp),\n         lgdp_pc=lgdp_pc - dplyr::lag(lgdp_pc)) %&gt;%\n  na.omit()\n\nm4 &lt;- lm(fd_lifeexp~ 0 + lgdp_pc , data=reg.dat)\nmodelsummary(list(\"Default FE\"=m1, \"Manual FE\"=m2, \"Default FD\"=m3, \"Manual FD\"=m4), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Default FE\n                Manual FE\n                Default FD\n                Manual FD\n              \n        \n        \n        \n                \n                  Log GDP per Capita\n                  9.769  \n                  9.769  \n                  5.290  \n                  5.290  \n                \n                \n                                    \n                  (0.702)\n                  (0.284)\n                  (0.291)\n                  (0.291)"
  },
  {
    "objectID": "slides/class9.html#fe-and-fd-with-same-time-period",
    "href": "slides/class9.html#fe-and-fd-with-same-time-period",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "FE and FD with same time period",
    "text": "FE and FD with same time period\n\n\nR Code\nreg.dat2 &lt;- causaldata::gapminder %&gt;%\n  mutate(lgdp_pc=log(gdpPercap)) %&gt;%\n  inner_join(reg.dat %&gt;% select(country, year), by=c(\"country\",\"year\"))\nm5 &lt;- feols(lifeExp ~ lgdp_pc | country, data=reg.dat2)\nmodelsummary(list(\"Default FE\"=m5, \"Default FD\"=m3, \"Manual FD\"=m4), \n             shape=term + statistic ~ model, \n             gof_map=NA, \n             coef_rename=c(\"lgdp_pc\"=\"Log GDP per Capita\"))\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Default FE\n                Default FD\n                Manual FD\n              \n        \n        \n        \n                \n                  Log GDP per Capita\n                  8.929  \n                  5.290  \n                  5.290  \n                \n                \n                                    \n                  (0.741)\n                  (0.291)\n                  (0.291)\n                \n        \n      \n    \n\n\n\nDon’t want to read too much into this, but…\n\nLikely strong serial correlation in this case (almost certainly)\nMispecified model"
  },
  {
    "objectID": "slides/class9.html#basic-2x2-setup",
    "href": "slides/class9.html#basic-2x2-setup",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Basic 2x2 Setup",
    "text": "Basic 2x2 Setup\nWant to estimate \\(ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]\\)\n\n\n\n\nPre-Period\nPost-Period\n\n\n\n\nTreatment\n\\(E(Y_{0}(0)|D=1)\\)\n\\(E(Y_{1}(1)|D=1)\\)\n\n\nControl\n\\(E(Y_{0}(0)|D=0)\\)\n\\(E(Y_{0}(1)|D=0)\\)\n\n\n\n\n\nProblem: We don’t see \\(E[Y_{0}(1)|D=1]\\)"
  },
  {
    "objectID": "slides/class9.html#basic-2x2-setup-1",
    "href": "slides/class9.html#basic-2x2-setup-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Basic 2x2 Setup",
    "text": "Basic 2x2 Setup\nWant to estimate \\(ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]\\)\n\n\n\n\nPre-Period\nPost-Period\n\n\n\n\nTreatment\n\\(E(Y_{0}(0)|D=1)\\)\n\\(E(Y_{1}(1)|D=1)\\)\n\n\nControl\n\\(E(Y_{0}(0)|D=0)\\)\n\\(E(Y_{0}(1)|D=0)\\)\n\n\n\n\n\nStrategy 1: Estimate \\(E[Y_{0}(1)|D=1]\\) using \\(E[Y_{0}(0)|D=1]\\) (before treatment outcome used to estimate post-treatment)"
  },
  {
    "objectID": "slides/class9.html#basic-2x2-setup-2",
    "href": "slides/class9.html#basic-2x2-setup-2",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Basic 2x2 Setup",
    "text": "Basic 2x2 Setup\nWant to estimate \\(ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]\\)\n\n\n\n\nPre-Period\nPost-Period\n\n\n\n\nTreatment\n\\(E(Y_{0}(0)|D=1)\\)\n\\(E(Y_{1}(1)|D=1)\\)\n\n\nControl\n\\(E(Y_{0}(0)|D=0)\\)\n\\(E(Y_{0}(1)|D=0)\\)\n\n\n\n\n\nStrategy 2: Estimate \\(E[Y_{0}(1)|D=1]\\) using \\(E[Y_{0}(1)|D=0]\\) (control group used to predict outcome for treatment)"
  },
  {
    "objectID": "slides/class9.html#basic-2x2-setup-3",
    "href": "slides/class9.html#basic-2x2-setup-3",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Basic 2x2 Setup",
    "text": "Basic 2x2 Setup\nWant to estimate \\(ATT = E[Y_{1}(1)- Y_{0}(1) | D=1]\\)\n\n\n\n\nPre-Period\nPost-Period\n\n\n\n\nTreatment\n\\(E(Y_{0}(0)|D=1)\\)\n\\(E(Y_{1}(1)|D=1)\\)\n\n\nControl\n\\(E(Y_{0}(0)|D=0)\\)\n\\(E(Y_{0}(1)|D=0)\\)\n\n\n\n\n\nStrategy 3: DD\n\nEstimate \\(E[Y_{1}(1)|D=1] - E[Y_{0}(1)|D=1]\\) using \\(E[Y_{0}(1)|D=0] - E[Y_{0}(0)|D=0]\\) (pre-post difference in control group used to predict difference for treatment group)"
  },
  {
    "objectID": "slides/class9.html#graphically",
    "href": "slides/class9.html#graphically",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Graphically",
    "text": "Graphically\n\n\n\nBasic DD Graph"
  },
  {
    "objectID": "slides/class9.html#animations",
    "href": "slides/class9.html#animations",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Animations",
    "text": "Animations\n\n\n\nBasic DD Graph, Animated"
  },
  {
    "objectID": "slides/class9.html#ate-estimates-with-dd",
    "href": "slides/class9.html#ate-estimates-with-dd",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "ATE Estimates with DD",
    "text": "ATE Estimates with DD\nKey identifying assumption is that of parallel trends\n\\[E[Y_{0}(1) - Y_{0}(0)|D=1] = E[Y_{0}(1) - Y_{0}(0)|D=0]\\]"
  },
  {
    "objectID": "slides/class9.html#estimation-sample-means",
    "href": "slides/class9.html#estimation-sample-means",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Estimation: Sample Means",
    "text": "Estimation: Sample Means\n\\[\\begin{align}\nE[Y_{1}(1) - Y_{0}(1)|D=1] &=& \\left( E[Y(1)|D=1] - E[Y(1)|D=0] \\right) \\\\\n& & - \\left( E[Y(0)|D=1] - E[Y(0)|D=0]\\right)\n\\end{align}\\]"
  },
  {
    "objectID": "slides/class9.html#estimation-regression",
    "href": "slides/class9.html#estimation-regression",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Estimation: Regression",
    "text": "Estimation: Regression\n\\[y_{it} = \\alpha + \\beta D_{i} + \\lambda \\times Post_{t} + \\delta \\times D_{i} \\times Post_{t} + \\varepsilon_{it}\\]\n\n\n\n\n\n\n\n\n\n\n\nPre\nPost\nPost - Pre\n\n\n\n\nTreatment\n\\(\\alpha + \\beta\\)\n\\(\\alpha + \\beta + \\lambda + \\delta\\)\n\\(\\lambda + \\delta\\)\n\n\nControl\n\\(\\alpha\\)\n\\(\\alpha + \\lambda\\)\n\\(\\lambda\\)\n\n\nDiff\n\\(\\beta\\)\n\\(\\beta + \\delta\\)\n\\(\\delta\\)"
  },
  {
    "objectID": "slides/class9.html#simulated-data",
    "href": "slides/class9.html#simulated-data",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Simulated data",
    "text": "Simulated data\n\nN &lt;- 5000\ndd.dat &lt;- tibble(\n  d = (runif(N, 0, 1)&gt;0.5),\n  time_pre = \"pre\",\n  time_post = \"post\"\n)\n\ndd.dat &lt;- pivot_longer(dd.dat, c(\"time_pre\",\"time_post\"), values_to=\"time\") %&gt;%\n  select(d, time) %&gt;%\n  mutate(t=(time==\"post\"),\n         y.out=1.5+3*d + 1.5*t + 6*d*t + rnorm(N*2,0,1))"
  },
  {
    "objectID": "slides/class9.html#mean-differences",
    "href": "slides/class9.html#mean-differences",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Mean differences",
    "text": "Mean differences\n\n\nR Code\ndd.means &lt;- dd.dat %&gt;% group_by(d, t) %&gt;% summarize(mean_y = mean(y.out)) %&gt;% mutate(d=ifelse(d==TRUE, \"Treated\", \"Control\"), t=ifelse(t==TRUE, \"Post\", \"Pre\"))\n\n\n`summarise()` has grouped output by 'd'. You can override using the `.groups`\nargument.\n\n\nR Code\nknitr::kable(dd.means, col.names=c(\"Treated\",\"Period\",\"Mean\"), format=\"html\")\n\n\n\n\n\nTreated\nPeriod\nMean\n\n\n\n\nControl\nPre\n1.525407\n\n\nControl\nPost\n2.985241\n\n\nTreated\nPre\n4.486714\n\n\nTreated\nPost\n12.004374"
  },
  {
    "objectID": "slides/class9.html#mean-differences-1",
    "href": "slides/class9.html#mean-differences-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Mean differences",
    "text": "Mean differences\nIn this example:\n\n\\(E[Y(1)|D=1] - E[Y(1)|D=0]\\) is 9.0191329\n\\(E[Y(0)|D=1] - E[Y(0)|D=0]\\) is 2.9613066\n\n\nSo the ATT is 6.0578263"
  },
  {
    "objectID": "slides/class9.html#regression-estimator",
    "href": "slides/class9.html#regression-estimator",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Regression estimator",
    "text": "Regression estimator\n\n\nR Code\nlibrary(modelsummary)\ndd.est &lt;- lm(y.out ~ d + t + d*t, data=dd.dat)\nmodelsummary(dd.est, gof_map=NA, coef_omit='Intercept')\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  dTRUE        \n                  2.961  \n                \n                \n                               \n                  (0.028)\n                \n                \n                  tTRUE        \n                  1.460  \n                \n                \n                               \n                  (0.028)\n                \n                \n                  dTRUE × tTRUE\n                  6.058  \n                \n                \n                               \n                  (0.040)"
  },
  {
    "objectID": "slides/class9.html#application",
    "href": "slides/class9.html#application",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Application",
    "text": "Application\n\nTry out some real data on Medicaid expansion following the ACA\nData is small part of DD empirical assignment\nQuestion: Did Medicaid expansion reduce uninsurance?"
  },
  {
    "objectID": "slides/class9.html#step-1-look-at-the-data",
    "href": "slides/class9.html#step-1-look-at-the-data",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Step 1: Look at the data",
    "text": "Step 1: Look at the data\n\n\nStata\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ncollapse (mean) perc_unins, by(year expand_ever)\ngraph twoway (connected perc_unins year if expand_ever==\"FALSE\", color(black) lpattern(solid)) ///\n  (connected perc_unins year if expand_ever==\"TRUE\", color(black) lpattern(dash)), ///\n  xline(2013.5) ///\n    ytitle(\"Fraction Uninsured\") xtitle(\"Year\") legend(off) text(0.15 2017 \"Non-expansion\", place(e)) text(0.08 2017 \"Expansion\", place(e))\n\n\nR\n\nlibrary(tidyverse)  \nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nins.plot.dat &lt;- mcaid.data %&gt;% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop) %&gt;%\n  group_by(expand_ever, year) %&gt;% summarize(mean=mean(perc_unins))\n\n`summarise()` has grouped output by 'expand_ever'. You can override using the\n`.groups` argument.\n\nins.plot &lt;- ggplot(data=ins.plot.dat, aes(x=year,y=mean,group=expand_ever,linetype=expand_ever)) + \n  geom_line() + geom_point() + theme_bw() +\n  geom_vline(xintercept=2013.5, color=\"red\") +\n  geom_text(data = ins.plot.dat %&gt;% filter(year == 2016), \n            aes(label = c(\"Non-expansion\",\"Expansion\"),\n                x = year + 1,\n                y = mean)) +\n  guides(linetype=\"none\") +\n  labs(\n    x=\"Year\",\n    y=\"Fraction Uninsured\",\n    title=\"Share of Uninsured over Time\"\n  )"
  },
  {
    "objectID": "slides/class9.html#step-1-look-at-the-data-1",
    "href": "slides/class9.html#step-1-look-at-the-data-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Step 1: Look at the data",
    "text": "Step 1: Look at the data"
  },
  {
    "objectID": "slides/class9.html#step-2-estimate-effects",
    "href": "slides/class9.html#step-2-estimate-effects",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Step 2: Estimate effects",
    "text": "Step 2: Estimate effects\nInterested in \\(\\delta\\) from:\n\\[y_{it} = \\alpha + \\beta \\times Post_{t} + \\lambda \\times Expand_{i} + \\delta \\times Post_{t} \\times Expand_{i} + \\varepsilon_{it}\\]\n\n\nStata\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ngen post=(year&gt;=2014)\ngen treat=(expand_ever==\"TRUE\")\ngen treat_post=(expand==\"TRUE\")\n\nreg perc_unins treat post treat_post\n\n**also try didregress\n\n\nR\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever)\n\ndd.ins.reg &lt;- lm(perc_unins ~ post + expand_ever + post*expand_ever, data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#step-2-estimate-effects-1",
    "href": "slides/class9.html#step-2-estimate-effects-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Step 2: Estimate effects",
    "text": "Step 2: Estimate effects\n\n\nR Code\nmodelsummary(list(\"DD (2014)\"=dd.ins.reg),\n             shape=term + statistic ~ model, \n             gof_map=NA,\n             coef_omit='Intercept',\n             vcov=~State\n         )\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                DD (2014)\n              \n        \n        \n        \n                \n                  postTRUE                  \n                  -0.054 \n                \n                \n                                            \n                  (0.003)\n                \n                \n                  expand_everTRUE           \n                  -0.046 \n                \n                \n                                            \n                  (0.016)\n                \n                \n                  postTRUE × expand_everTRUE\n                  -0.019 \n                \n                \n                                            \n                  (0.007)"
  },
  {
    "objectID": "slides/class9.html#final-dd-thoughts",
    "href": "slides/class9.html#final-dd-thoughts",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Final DD thoughts",
    "text": "Final DD thoughts\n\nKey identification assumption is parallel trends\nInference: Typically want to cluster at unit-level to allow for correlation over time within units, but problems with small numbers of treated or control groups:\n\nConley-Taber CIs\nWild cluster bootstrap\nRandomization inference\n\n“Extra” things like propensity score weighting and doubly robust estimation"
  },
  {
    "objectID": "slides/class9.html#dd-and-twfe",
    "href": "slides/class9.html#dd-and-twfe",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "DD and TWFE?",
    "text": "DD and TWFE?\n\nJust a shorthand for a common regression specification\nFixed effects for each unit and each time period, \\(\\gamma_{i}\\) and \\(\\gamma_{t}\\)\nMore general than 2x2 DD but same result"
  },
  {
    "objectID": "slides/class9.html#what-is-twfe",
    "href": "slides/class9.html#what-is-twfe",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "What is TWFE?",
    "text": "What is TWFE?\nWant to estimate \\(\\delta\\):\n\\[y_{it} = \\alpha + \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\varepsilon_{it},\\]\nwhere \\(\\gamma_{i}\\) and \\(\\gamma_{t}\\) denote a set of unit \\(i\\) and time period \\(t\\) dummy variables (or fixed effects)."
  },
  {
    "objectID": "slides/class9.html#twfe-in-practice",
    "href": "slides/class9.html#twfe-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "TWFE in Practice",
    "text": "TWFE in Practice\n\n\n2x2 DD\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever)\nm.dd &lt;- lm(perc_unins ~ post + expand_ever + treat, data=reg.dat)\n\n\nTWFE\n\nlibrary(fixest)\nm.twfe &lt;- feols(perc_unins ~ treat | State + year, data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#twfe-in-practice-1",
    "href": "slides/class9.html#twfe-in-practice-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "TWFE in Practice",
    "text": "TWFE in Practice\n\n\nR Code\nmsummary(list(\"DD\"=m.dd, \"TWFE\"=m.twfe),\n         shape=term + statistic ~ model, \n         gof_map=NA,\n         coef_omit='Intercept',\n         vcov=~State\n         )\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                DD\n                TWFE\n              \n        \n        \n        \n                \n                  postTRUE       \n                  -0.054 \n                         \n                \n                \n                                 \n                  (0.003)\n                         \n                \n                \n                  expand_everTRUE\n                  -0.046 \n                         \n                \n                \n                                 \n                  (0.016)\n                         \n                \n                \n                  treat          \n                  -0.019 \n                  -0.019 \n                \n                \n                                 \n                  (0.007)\n                  (0.007)"
  },
  {
    "objectID": "slides/class9.html#event-study",
    "href": "slides/class9.html#event-study",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Event study",
    "text": "Event study\nEvent study is poorly named:\n\nIn finance, even study is just an interrupted time series\nIn econ and other areas, we usually have a treatment/control group and a break in time"
  },
  {
    "objectID": "slides/class9.html#why-show-an-event-study",
    "href": "slides/class9.html#why-show-an-event-study",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Why show an event study?",
    "text": "Why show an event study?\n\nAllows for heterogeneous effects over time (maybe effects phase in over time or dissipate)\nVisually very appealing\nOffers easy evidence against or consistent with parallel trends assumption"
  },
  {
    "objectID": "slides/class9.html#how-to-do-an-event-study",
    "href": "slides/class9.html#how-to-do-an-event-study",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "How to do an event study?",
    "text": "How to do an event study?\nEstimate something akin to… \\[y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{\\tau = -q}^{-2}\\delta_{\\tau} D_{i \\tau} + \\sum_{\\tau=0}^{m} \\delta_{\\tau}D_{i \\tau} + \\beta x_{it} + \\epsilon_{it},\\]\nwhere \\(q\\) captures the number of periods before the treatment occurs and \\(m\\) captures periods after treatment occurs."
  },
  {
    "objectID": "slides/class9.html#how-to-do-an-event-study-1",
    "href": "slides/class9.html#how-to-do-an-event-study-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "How to do an event study?",
    "text": "How to do an event study?\n\nCreate all treatment/year interactions\nRegressions with full set of interactions and group/year FEs\nPlot coefficients and standard errors"
  },
  {
    "objectID": "slides/class9.html#things-to-address",
    "href": "slides/class9.html#things-to-address",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Things to address",
    "text": "Things to address\n\n“Event time” vs calendar time\nDefine baseline period\nChoose number of pre-treatment and post-treatment coefficients"
  },
  {
    "objectID": "slides/class9.html#event-time-vs-calendar-time",
    "href": "slides/class9.html#event-time-vs-calendar-time",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Event time vs calendar time",
    "text": "Event time vs calendar time\nEssentially two “flavors” of event studies\n\nCommon treatment timing\nDifferential treatment timing"
  },
  {
    "objectID": "slides/class9.html#define-baseline-period",
    "href": "slides/class9.html#define-baseline-period",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Define baseline period",
    "text": "Define baseline period\n\nMust choose an “excluded” time period (as in all cases of group dummy variables)\nCommon choice is \\(t=-1\\) (period just before treatment)\nEasy to understand with calendar time\nFor event time…manually set time to \\(t=-1\\) for all untreated units"
  },
  {
    "objectID": "slides/class9.html#number-of-pre-treatment-and-post-treatment-periods",
    "href": "slides/class9.html#number-of-pre-treatment-and-post-treatment-periods",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Number of pre-treatment and post-treatment periods",
    "text": "Number of pre-treatment and post-treatment periods\n\nOn event time, sometimes very few observations for large lead or lag values\nMedicaid expansion example: Late adopting states have fewer post-treatment periods\nNorm is to group final lead/lag periods together"
  },
  {
    "objectID": "slides/class9.html#commont-treatment-timing",
    "href": "slides/class9.html#commont-treatment-timing",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Commont treatment timing",
    "text": "Commont treatment timing\n\n\nStata\n\nssc install reghdfe\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\nkeep if expand_year==\"2014\" | expand_year==\"NA\"\ndrop if expand_ever==\"NA\"\ngen post=(year&gt;=2014)\ngen treat=(expand_ever==\"TRUE\")\ngen treat_post=(expand==\"TRUE\")\n\nreghdfe perc_unins treat##ib2013.year, absorb(state)\ngen coef = .\ngen se = .\nforvalues i = 2012(1)2018 {\n    replace coef = _b[1.treat#`i'.year] if year == `i'\n    replace se = _se[1.treat#`i'.year] if year == `i'\n}\n\n* Make confidence intervals\ngen ci_top = coef+1.96*se\ngen ci_bottom = coef - 1.96*se\n\n* Limit ourselves to one observation per year\nkeep year coef se ci_*\nduplicates drop\n\n* Create connected scatterplot of coefficients\n* with CIs included with rcap \n* and a line at 0 from function\ntwoway (sc coef year, connect(line)) (rcap ci_top ci_bottom year) ///\n    (function y = 0, range(2012 2018)), xtitle(\"Year\") ///\n    caption(\"Estimates and 95% CI from Event Study\")\n\n\nR\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever)\n\nmod.twfe &lt;- feols(perc_unins~i(year, expand_ever, ref=2013) | State + year,\n                  cluster=~State,\n                  data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#common-treatment-timing",
    "href": "slides/class9.html#common-treatment-timing",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Common treatment timing",
    "text": "Common treatment timing\n\n\nR Code\niplot(mod.twfe, \n      xlab = 'Time to treatment',\n      main = 'Event study')"
  },
  {
    "objectID": "slides/class9.html#differential-treatment-timing",
    "href": "slides/class9.html#differential-treatment-timing",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Differential treatment timing",
    "text": "Differential treatment timing\n\nNow let’s work with the full Medicaid expansion data\nIncludes late adopters\nRequires putting observations on “event time”"
  },
  {
    "objectID": "slides/class9.html#differential-treatment-timing-1",
    "href": "slides/class9.html#differential-treatment-timing-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Differential treatment timing",
    "text": "Differential treatment timing\n\n\nStata\n\nssc install reghdfe\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\nreplace event_time=-1 if event_time==.\n\nforvalues l = 0/4 {\n    gen L`l'event = (event_time==`l')\n}\nforvalues l = 1/2 {\n    gen F`l'event = (event_time==-`l')\n}\ngen F3event=(event_time&lt;=-3)\n\nreghdfe perc_unins F3event F2event L0event L1event L2event L3event L4event, absorb(state year) cluster(state)\ngen coef = .\ngen se = .\nforvalues i = 2(1)3 {\n    replace coef = _b[F`i'event] if F`i'event==1\n    replace se = _se[F`i'event] if F`i'event==1\n}\nforvalues i = 0(1)4 {\n    replace coef = _b[L`i'event] if L`i'event==1\n    replace se = _se[L`i'event] if L`i'event==1\n}\nreplace coef = 0 if F1event==1\nreplace se=0 if F1event==1\n\n* Make confidence intervals\ngen ci_top = coef+1.96*se\ngen ci_bottom = coef - 1.96*se\n\n* Limit ourselves to one observation per year\nkeep if event_time&gt;=-3 & event_time&lt;=4\nkeep event_time coef se ci_*\nduplicates drop\n\n* Create connected scatterplot of coefficients\n* with CIs included with rcap \n* and a line at 0 from function\nsort event_time\ntwoway (sc coef event_time, connect(line)) (rcap ci_top ci_bottom event_time) ///\n    (function y = 0, range(-3 4)), xtitle(\"Time\") ///\n    caption(\"Estimates and 95% CI from Event Study\") xlabel(-3(1)4)\n\n\nR\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(!is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever,\n         time_to_treat = ifelse(expand_ever==FALSE, 0, year-expand_year),\n         time_to_treat = ifelse(time_to_treat &lt; -3, -3, time_to_treat))\n\nmod.twfe &lt;- feols(perc_unins~i(time_to_treat, expand_ever, ref=-1) | State + year,\n                  cluster=~State,\n                  data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#differential-treatment-timing-2",
    "href": "slides/class9.html#differential-treatment-timing-2",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Differential treatment timing",
    "text": "Differential treatment timing\n\n\nR Code\niplot(mod.twfe, \n      xlab = 'Time to treatment',\n      main = 'Event study')"
  },
  {
    "objectID": "slides/class9.html#problems-with-twfe",
    "href": "slides/class9.html#problems-with-twfe",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Problems with TWFE",
    "text": "Problems with TWFE\n\nRecall goal of estimating ATE or ATT\nTWFE and 2x2 DD identical with homogeneous effects and common treatment timing\nOtherwise…TWFE is biased and inconsistent for ATT\n\nConsider standard TWFE specification with a single treatment coefficient, \\[y_{it} = \\alpha + \\delta D_{it} + \\gamma_{i} + \\gamma_{t} + \\varepsilon_{it}.\\] We can decompose \\(\\hat{\\delta}\\) into three things:\n\\[\\hat{\\delta}_{twfe} = \\text{VW} ATT + \\text{VW} PT - \\Delta ATT\\]\n\nA variance-weighted ATT\nViolation of parallel trends\nHeterogeneous effects over time"
  },
  {
    "objectID": "slides/class9.html#intuition",
    "href": "slides/class9.html#intuition",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Intuition",
    "text": "Intuition\nProblems come from heterogeneous effects and staggered treatment timing\n\nOLS is a weighted average of all 2x2 DD groups\nWeights are function of size of subsamples, size of treatment/control units, and timing of treatment\nUnits treated in middle of sample receive larger weights\nBest case: Variance-weighted ATT\nPrior-treated units act as controls for late-treated units, so differential timing alone can introduce bias\nHeterogeneity and differential timing introduces “contamination” via negative weights assigned to some underlying 2x2 DDs"
  },
  {
    "objectID": "slides/class9.html#does-it-really-matter",
    "href": "slides/class9.html#does-it-really-matter",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Does it really matter?",
    "text": "Does it really matter?\n\nDefinitely! But how much?\nLarge treatment effects for early treated units could reverse the sign of final estimate\nLet’s explore this nice Shiny app from Kyle Butts: Bacon-Decomposition Shiny App."
  },
  {
    "objectID": "slides/class9.html#solution",
    "href": "slides/class9.html#solution",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Solution",
    "text": "Solution\nOnly consider “clean” comparisons:\n\nSeparate event study for each treatment group vs never-treated or not-yet-treated\nCallaway and Sant’Anna (2020)\nSun and Abraham (2020)\nde Chaisemartin and D’Haultfoeuille (2020)\nStacking regression: Cengiz et al. (2019)\nImputation: Gardner (2021), and Borusyak et al. (2021)"
  },
  {
    "objectID": "slides/class9.html#changing-mindset-for-estimation",
    "href": "slides/class9.html#changing-mindset-for-estimation",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Changing mindset for estimation",
    "text": "Changing mindset for estimation\n\nDefine target parameter (e.g., ATT)…this is pretty new as a starting point\nIdentification\nEstimation\nAggregation\nInference"
  },
  {
    "objectID": "slides/class9.html#incorporating-covariates",
    "href": "slides/class9.html#incorporating-covariates",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Incorporating covariates",
    "text": "Incorporating covariates\n\n“Easy” to do in regression setting, but risks of using outcomes as controls\nTwo general ways:\n\nOutcome regression (imputation-based)\nPropensity score"
  },
  {
    "objectID": "slides/class9.html#outcome-regression-heckman-et-al-1997",
    "href": "slides/class9.html#outcome-regression-heckman-et-al-1997",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Outcome regression (Heckman et al 1997)",
    "text": "Outcome regression (Heckman et al 1997)\n\\[\\small \\hat{\\delta}^{reg} = E[Y_{t=1}|D=1] - \\left[ E[Y_{t=0}|D=1] + \\frac{1}{n^{T}} \\sum_{i \\in N_{d=1}} \\left(\\hat{\\mu}_{d=0, t=1}(X_{i}) - \\hat{\\mu}_{d=0, t=0}(X_{i})\\right) \\right],\\]\nwhere \\(\\hat{\\mu}_{d,t}\\) is the prediction from a regression among the untreated group using baseline covariates.\n\nHeckman forms prediction as regression of \\(\\Delta Y\\) on \\(X_{i}\\) among untreated group, although could also consider separate regressions on levels\nConceptually…take observed value among treatment group in post-period, subtract pre-period value and the predicted trend"
  },
  {
    "objectID": "slides/class9.html#ipw-abadie-2005",
    "href": "slides/class9.html#ipw-abadie-2005",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "IPW (Abadie, 2005)",
    "text": "IPW (Abadie, 2005)\n\\[\\hat{\\delta}^{ipw} = E \\left[\\frac{D - \\hat{p}(D=1|X)}{1-\\hat{p}(D=1|X)} \\frac{Y_{t=1} - Y_{t=0}}{P(D=1)} \\right]\\]\n\n\\(Y_{t=1}\\) is the observed outcome at time \\(t=1\\), and similarly for \\(Y_{t=0}\\)\n\\(\\hat{p}\\) denotes the estimated propensity score from regression of \\(D\\) on \\(X\\) in pre-period\nConceptually…upweight change among treated that look a lot like the control group, downweight change among treated that look different than controls"
  },
  {
    "objectID": "slides/class9.html#dr-santanna-and-zhou",
    "href": "slides/class9.html#dr-santanna-and-zhou",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "DR (Sant’Anna and Zhou)",
    "text": "DR (Sant’Anna and Zhou)\n\\[\\scriptsize \\hat{\\delta}^{dr} = E \\left[ \\left(\\frac{D}{P(D=1)} - \\frac{\\frac{\\hat{p}(X)(1-D)}{1-\\hat{p}(X)}}{E\\left[\\frac{\\hat{p}(X)(1-D)}{1-\\hat{p}(X)} \\right]} \\right) \\left(E[Y_{t=1}|D=1] - E[Y_{t=0}|D=1] - \\Delta \\hat{\\mu}_{0}(X)\\right) \\right]\\]\n\nNotice how this combines Heckman’s outcome regression in the second part and Abadie’s IPW in the first part"
  },
  {
    "objectID": "slides/class9.html#the-new-dd",
    "href": "slides/class9.html#the-new-dd",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "The New DD",
    "text": "The New DD\nI’ll organize this into three types of estimators:\n\nGroup-time comparisons (GT)\nStacked\nImputation"
  },
  {
    "objectID": "slides/class9.html#gt1-callaway-and-santanna",
    "href": "slides/class9.html#gt1-callaway-and-santanna",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT1: Callaway and Sant’Anna",
    "text": "GT1: Callaway and Sant’Anna\n\n“Manually” estimate group-specific treatment effects for each period\nEach estimate is propensity-score weighted\nAggregate the treatment effect estimates (by time, group, or both)"
  },
  {
    "objectID": "slides/class9.html#gt1-cs-estimator-more-formally",
    "href": "slides/class9.html#gt1-cs-estimator-more-formally",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT1: CS Estimator (More Formally)",
    "text": "GT1: CS Estimator (More Formally)\nGroup-specific treatment effects:\n\\[ATT(g,t) = E[Y_{1,t} - Y_{0,t} | G_{g}=1],\\] where \\(G\\) denotes all feasible groups or cohorts (e.g., \\(g=1\\) could mean states expanding in 2014, \\(g=2\\) denotes states expanding in 2015, etc.)"
  },
  {
    "objectID": "slides/class9.html#gt1-cs-estimator-more-formally-1",
    "href": "slides/class9.html#gt1-cs-estimator-more-formally-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT1: CS Estimator (More Formally)",
    "text": "GT1: CS Estimator (More Formally)\nWith this \\((g,t)\\) notation, CS show:\n\\[\\scriptsize ATT(g,t; \\tau)^{DR} = E \\left[ \\left(\\frac{G_{g}}{P(G_{g}=1)} - \\frac{\\frac{\\hat{p}_{g}(X)C}{1-\\hat{p}_{g}(X)}}{E\\left[\\frac{\\hat{p}_{g}(X)C}{1-\\hat{p}_{g}(X)} \\right]} \\right) \\left(E[Y_{t}|G_{g}=1] - E[Y_{g-\\tau-1}|G_{g}=1] - \\Delta \\hat{\\mu}_{g,t,\\tau}(X)\\right) \\right]\\]\n\n\\(\\tau\\) denotes time from treatment, such that \\(Y_{g - \\tau - 1}\\) denotes the outcome for some reference time period, \\(t=g - \\tau -1\\)\n\\(\\Delta \\hat{\\mu}\\) captures the predicted change from an outcome regression\n\\(\\hat{p}_{g}\\) denotes the predicted probability of being in the treatment cohort \\(g\\)"
  },
  {
    "objectID": "slides/class9.html#gt1-cs-estimator-more-formally-2",
    "href": "slides/class9.html#gt1-cs-estimator-more-formally-2",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT1: CS Estimator (More Formally)",
    "text": "GT1: CS Estimator (More Formally)\n\nCS show a similar version of their estimator using a “not-yet-treated” control group rather than a never-treated.\nDifferent versions include…\n\n“regression” based: drop the propensity score part\n“IPW”: drop \\(\\Delta \\hat{\\mu}\\)\n\nOnly time-invariant covariates allowed"
  },
  {
    "objectID": "slides/class9.html#gt1-cs-estimator-more-formally-3",
    "href": "slides/class9.html#gt1-cs-estimator-more-formally-3",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT1: CS Estimator (More Formally)",
    "text": "GT1: CS Estimator (More Formally)\nFinally, aggregate all of the \\((g,t)\\) treatment effects:\n\\[\\hat{\\delta} = \\sum_{g \\in \\mathcal{G}} \\sum_{t=2}^{\\mathcal{T}} w(g,t) \\times ATT(g,t)\\]"
  },
  {
    "objectID": "slides/class9.html#gt1-cs-estimator-in-practice",
    "href": "slides/class9.html#gt1-cs-estimator-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT1: CS Estimator (in Practice)",
    "text": "GT1: CS Estimator (in Practice)\n\n\nStata\n\nssc install csdid\nssc install event_plot\nssc install drdid\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\negen stategroup=group(state)\ndrop if expand_ever==\"NA\"\nreplace expand_year=\"0\" if expand_year==\"NA\"\ndestring expand_year, replace\n\ncsdid perc_unins, ivar(stategroup) time(year) gvar(expand_year) notyet\nestat event, estore(cs)\nevent_plot cs, default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") xlabel(-6(1)4) title(\"Callaway and Sant'Anna (2020)\")) stub_lag(T+#) stub_lead(T-#) together\n\n\nR\n\nlibrary(tidyverse)\nlibrary(did)\nlibrary(DRDID)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(!is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever,\n         expand_year=ifelse(is.na(expand_year),0,expand_year)) %&gt;%\n  filter(!is.na(perc_unins)) %&gt;%\n  group_by(State) %&gt;%\n  mutate(stategroup=cur_group_id()) %&gt;% ungroup()\n\nmod.cs &lt;- att_gt(yname=\"perc_unins\", tname=\"year\", idname=\"stategroup\",\n                 gname=\"expand_year\",\n                 data=reg.dat, panel=TRUE, est_method=\"dr\",\n                 allow_unbalanced_panel=TRUE)\n\nWarning in pre_process_did(yname = yname, tname = tname, idname = idname, : Be aware that there are some small groups in your dataset.\n  Check groups: 2015,2016,2019.\n\n\nWarning in att_gt(yname = \"perc_unins\", tname = \"year\", idname = \"stategroup\",\n: Not returning pre-test Wald statistic due to singular covariance matrix\n\nmod.cs.event &lt;- aggte(mod.cs, type=\"dynamic\")"
  },
  {
    "objectID": "slides/class9.html#cs-in-practice",
    "href": "slides/class9.html#cs-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "CS in Practice",
    "text": "CS in Practice\n\n\nR Code\nggdid(mod.cs.event,\n      legend=FALSE)"
  },
  {
    "objectID": "slides/class9.html#gt2-sun-and-abraham",
    "href": "slides/class9.html#gt2-sun-and-abraham",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT2: Sun and Abraham",
    "text": "GT2: Sun and Abraham\n\nStandard event study problems:\n\ncoefficient estimates are potentially biased due to treatment/control group construction\ni.e., “contamination” of individual \\(\\delta_{\\tau}\\) from other leads/lags\n\nSolution: Estimate fully interacted model\n\n\n\\[y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{g} \\sum_{\\tau \\neq -1} \\delta_{g \\tau} \\times \\text{1}(i \\in C_{g}) \\times D_{it}^{\\tau} + \\beta x_{it} + \\epsilon_{it}\\]"
  },
  {
    "objectID": "slides/class9.html#gt2-sun-and-abraham-1",
    "href": "slides/class9.html#gt2-sun-and-abraham-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT2: Sun and Abraham",
    "text": "GT2: Sun and Abraham\n\\[y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{g} \\sum_{\\tau \\neq -1} \\delta_{g \\tau} \\times \\text{1}(i \\in C_{g}) \\times D_{it}^{\\tau} + \\beta x_{it} + \\epsilon_{it}\\]\n\n\n\\(g\\) denotes a group and \\(C_{g}\\) the set of individuals in group \\(g\\)\n\\(\\tau\\) denotes time periods\n\\(D_{it}^{\\tau}\\) denotes a relative time indicator"
  },
  {
    "objectID": "slides/class9.html#gt2-sun-and-abraham-2",
    "href": "slides/class9.html#gt2-sun-and-abraham-2",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT2: Sun and Abraham",
    "text": "GT2: Sun and Abraham\n\\[y_{it} = \\gamma_{i} + \\gamma_{t} + \\sum_{g} \\sum_{\\tau \\neq -1} \\delta_{g \\tau} \\times \\text{1}(i \\in C_{g}) \\times D_{it}^{\\tau} + \\beta x_{it} + \\epsilon_{it}\\]\n\n\nIntuition: Standard regression with different event study specifications for each treatment group\nAggregate \\(\\delta_{g\\tau}\\) for standard event study coefficients and overall ATT"
  },
  {
    "objectID": "slides/class9.html#gt2-sun-and-abraham-in-practice",
    "href": "slides/class9.html#gt2-sun-and-abraham-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT2: Sun and Abraham in Practice",
    "text": "GT2: Sun and Abraham in Practice\n\n\nStata\n\nssc install eventstudyinteract\nssc install avar\nssc install event_plot\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\negen stategroup=group(state)\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\ngen nevertreated=(event_time==.)\n\nforvalues l = 0/4 {\n    gen L`l'event = (event_time==`l')\n}\nforvalues l = 1/2 {\n    gen F`l'event = (event_time==-`l')\n}\ngen F3event=(event_time&lt;=-3)\neventstudyinteract perc_unins F3event F2event L0event L1event L2event L3event L4event, vce(cluster stategroup) absorb(stategroup year) cohort(expand_year) control_cohort(nevertreated)\n\nevent_plot e(b_iw)#e(V_iw), default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") xlabel(-3(1)4) title(\"Sun and Abraham (2020)\")) stub_lag(L#event) stub_lead(F#event) plottype(scatter) ciplottype(rcap) together\n\n\nR\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(!is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever,\n         expand_year = ifelse(expand_ever==FALSE, 10000, expand_year),\n         time_to_treat = ifelse(expand_ever==FALSE, -1, year-expand_year),\n         time_to_treat = ifelse(time_to_treat &lt; -4, -4, time_to_treat))\n\nmod.sa &lt;- feols(perc_unins~sunab(expand_year, time_to_treat) | State + year,\n                  cluster=~State,\n                  data=reg.dat)"
  },
  {
    "objectID": "slides/class9.html#sun-and-abraham-in-practice",
    "href": "slides/class9.html#sun-and-abraham-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Sun and Abraham in Practice",
    "text": "Sun and Abraham in Practice\n\n\nR Code\niplot(mod.sa,\n      xlab = 'Time to treatment',\n      main = 'SA Event study')"
  },
  {
    "objectID": "slides/class9.html#gt3-de-chaisemartin-and-dhaultfoeuille-ch",
    "href": "slides/class9.html#gt3-de-chaisemartin-and-dhaultfoeuille-ch",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT3: de Chaisemartin and D’Haultfoeuille (CH)",
    "text": "GT3: de Chaisemartin and D’Haultfoeuille (CH)\n\nMore general than other approaches\nConsiders “fuzzy” treatment (i.e., non-discrete treatment)\nConsiders fixed effects and first-differencing\nAllows treatment to turn on and off (not allowed in CS or SA)\n\n\nNew paper from Callaway, Goodman-Bacon, and Sant’Anna also looks at DD with continuous treatment"
  },
  {
    "objectID": "slides/class9.html#gt3-ch-approach",
    "href": "slides/class9.html#gt3-ch-approach",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "GT3: CH Approach",
    "text": "GT3: CH Approach\n\nEssentially a series of 2x2 comparisons\nAggregates up to overall effects"
  },
  {
    "objectID": "slides/class9.html#ch-in-practice",
    "href": "slides/class9.html#ch-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "CH in Practice",
    "text": "CH in Practice\n\n\nStata\n\nssc install did_multiplegt\nssc install event_plot\n\ninsheet using \"data/acs_medicaid.txt\", clear\ngen perc_unins=uninsured/adult_pop\ndrop if expand_ever==\"NA\"\negen stategroup=group(state)\nreplace expand_year=\".\" if expand_year==\"NA\"\ndestring expand_year, replace\ngen event_time=year-expand_year\ngen nevertreated=(event_time==.)\ngen treat=(event_time&gt;=0 & event_time!=.)\n\ndid_multiplegt perc_unins stategroup year treat, robust_dynamic dynamic(4) placebo(3) breps(100) cluster(stategroup) \nevent_plot e(estimates)#e(variances), default_look graph_opt(xtitle(\"Periods since the event\") ytitle(\"Average causal effect\") ///\ntitle(\"de Chaisemartin and D'Haultfoeuille (2020)\") xlabel(-3(1)4)) stub_lag(Effect_#) stub_lead(Placebo_#) together\n\n\nR(not the same as in Stata)\n\nlibrary(DIDmultiplegt)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(!is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         treat=case_when(\n           expand_ever==FALSE ~ 0,\n           expand_ever==TRUE & expand_year&lt;year ~ 0,\n           expand_ever==TRUE & expand_year&gt;=year ~ 1))\n\nmod.ch &lt;- did_multiplegt(df=reg.dat, Y=\"perc_unins\", G=\"State\", T=\"year\", D=\"treat\",\n                         placebo=4, dynamic=5, brep=50, cluster='State', covariance=TRUE, \n                         average_effect=\"simple\")"
  },
  {
    "objectID": "slides/class9.html#ch-in-practice-1",
    "href": "slides/class9.html#ch-in-practice-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "CH in Practice",
    "text": "CH in Practice\n\n\nR Code\nlibrary(broom)\n# Create a tidier for \"multiplegt\" objects\ntidy.did_multiplegt = function(x, level = 0.95) {\n  ests = x[grepl(\"^placebo_|^effect|^dynamic_\", names(x))]\n  ret = data.frame(\n    term      = names(ests),\n    estimate  = as.numeric(ests),\n    std.error = as.numeric(x[grepl(\"^se_placebo|^se_effect|^se_dynamic\", names(x))]),\n    N         = as.numeric(x[grepl(\"^N_placebo|^N_effect|^N_dynamic\", names(x))])\n    ) |&gt;\n    # For CIs we'll assume standard normal distribution\n    within({\n      conf.low  = estimate - std.error*(qnorm(1-(1-level)/2))\n      conf.high = estimate + std.error*(qnorm(1-(1-level)/2))\n      })\n  return(ret)\n}\n\ntidy.mod.ch &lt;- tidy.did_multiplegt(mod.ch)\n\nlibrary(ggplot2)\ntheme_set(theme_minimal(base_family = \"ArialNarrow\")) # Optional\ntidy.mod.ch |&gt;\n  within({\n    term = gsub(\"^placebo_\", \"-\", term)\n    term = gsub(\"^effect\", \"0\", term)\n    term = gsub(\"^dynamic_\", \"\", term)\n    term = as.integer(term)\n    }) |&gt;\n  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +\n  geom_pointrange() +\n  labs(\n    x = \"Time to treatment\", y = \"Effect size\", title = \"CH Event-study plot\"\n    )"
  },
  {
    "objectID": "slides/class9.html#ch-in-practice-2",
    "href": "slides/class9.html#ch-in-practice-2",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "CH in practice",
    "text": "CH in practice\nSome barriers to this estimator in practice (at least, as implemented in R right now)\n\nRelatively slow\nNot user friendly\nOdd results"
  },
  {
    "objectID": "slides/class9.html#cengiz-et-al.-2019-stacked-regression",
    "href": "slides/class9.html#cengiz-et-al.-2019-stacked-regression",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Cengiz et al. (2019): Stacked regression",
    "text": "Cengiz et al. (2019): Stacked regression\n\n“Stacked” event studies\nEstimate event study for every treatment group, using never-treated as controls\nAggregate to overall average effects"
  },
  {
    "objectID": "slides/class9.html#cengiz-et-al.-2019",
    "href": "slides/class9.html#cengiz-et-al.-2019",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Cengiz et al. (2019)",
    "text": "Cengiz et al. (2019)\n\nDefine event window, \\(t\\in [\\kappa_{a}, \\kappa_{b}]\\) (e.g., 3 pre-periods and 5 post-periods, \\(\\kappa_{a}=3\\) and \\(\\kappa_{b}=5\\))\nSplit the data into \\(g=1,...,G\\) different “groups”, as defined by treatment cohort, each with adoption date denoted by \\(\\omega_{g}\\)\n\nobservations outside of the \\([\\omega_{g} - \\kappa_{a}, \\omega_{g} + \\kappa_{b}]\\) interval are dropped\n\nAppend (i.e., stack) each \\(g\\)th dataset\nRun stacked event study allowing for different set of event study coefficients and fixed effects for every group \\(g\\)\n\n\\[y_{itg} = \\sum_{\\tau=-\\kappa_{a}}^{\\kappa_{b}} \\delta_{\\tau} \\times D_{ig} \\times 1(t-\\omega_{g} = \\tau) + \\gamma_{ig} + \\gamma_{\\tau g} + \\varepsilon_{itg}\\]"
  },
  {
    "objectID": "slides/class9.html#cengiz-et-al.-2019-1",
    "href": "slides/class9.html#cengiz-et-al.-2019-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Cengiz et al. (2019)",
    "text": "Cengiz et al. (2019)\n\nIntuitively: run event study on every cohort, \\(g\\)\nControl units (never treated or very late treated) will be duplicated over cohorts\nNeed to cluster at the unit or unit/cohort level (probably unit level otherwise not accounting for duplication)\nAlternative: Among controls included in multiple cohorts, randomly assign them to one cohort"
  },
  {
    "objectID": "slides/class9.html#quick-comparison",
    "href": "slides/class9.html#quick-comparison",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Quick comparison",
    "text": "Quick comparison\n\nAllows time-varying covariates\nInference is less clear\nLikely estimating some variance-weighted ATT…not clear what those weights are anymore\nSeemingly stronger parallel trends assumptions for each cohort"
  },
  {
    "objectID": "slides/class9.html#imputation-estimators",
    "href": "slides/class9.html#imputation-estimators",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Imputation estimators",
    "text": "Imputation estimators\n\nEstimate group and time fixed effects via first stage regression only among non-treated units\nPredict outcome for all observations and residualize\nRun standard event study specification on residualized outcome variable\n\nNote: Estimate with GMM to account for first-stage prediction"
  },
  {
    "objectID": "slides/class9.html#gardner-2021",
    "href": "slides/class9.html#gardner-2021",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Gardner (2021)",
    "text": "Gardner (2021)\n\n\nStata\ndid2s\n\nR\n\nlibrary(did2s)\n\ndid2s (v1.0.2). For more information on the methodology, visit &lt;https://www.kylebutts.github.io/did2s&gt;\n\nTo cite did2s in publications use:\n\n  Butts, Kyle (2021).  did2s: Two-Stage Difference-in-Differences\n  Following Gardner (2021). R package version 1.0.2.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {did2s: Two-Stage Difference-in-Differences Following Gardner (2021)},\n    author = {Kyle Butts},\n    year = {2021},\n    url = {https://github.com/kylebutts/did2s/},\n  }\n\n\n\nAttaching package: 'did2s'\n\n\nThe following object is masked from 'package:causaldata':\n\n    castle\n\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(!is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever,\n         expand_year = ifelse(expand_ever==FALSE, 10000, expand_year),\n         time_to_treat = ifelse(expand_ever==FALSE, -1, year-expand_year),\n         time_to_treat = ifelse(time_to_treat &lt; -3, -3, time_to_treat))\n\nmod.2s &lt;- did2s(reg.dat, yname=\"perc_unins\", \n                treatment=\"treat\", \n                first_stage = ~ 0 | State + year,\n                second_stage = ~i(time_to_treat, ref=-1),\n                cluster_var=\"State\")\n\nRunning Two-stage Difference-in-Differences\n - first stage formula `~ 0 | State + year`\n - second stage formula `~ i(time_to_treat, ref = -1)`\n - The indicator variable that denotes when treatment is on is `treat`\n - Standard errors will be clustered by `State`"
  },
  {
    "objectID": "slides/class9.html#gardner-2021-in-practice",
    "href": "slides/class9.html#gardner-2021-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Gardner (2021) in Practice",
    "text": "Gardner (2021) in Practice\n\n\nR Code\niplot(mod.2s, main=\"2SDID Event Study\", xlab=\"Event time\")"
  },
  {
    "objectID": "slides/class9.html#borusyak-et-al.-2021",
    "href": "slides/class9.html#borusyak-et-al.-2021",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Borusyak et al. (2021)",
    "text": "Borusyak et al. (2021)\n\nEstimate regression only for untreated observations\nPredicted untreated outcome among the treated observations and take the difference\nAggregate differences to form overall weighted average effect"
  },
  {
    "objectID": "slides/class9.html#borusyak-et-al.-in-practice",
    "href": "slides/class9.html#borusyak-et-al.-in-practice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Borusyak et al. in practice",
    "text": "Borusyak et al. in practice\n\n\nStata\ndid_imputation\n\nR\n\nlibrary(didimputation)\n\nLoading required package: data.table\n\n\n\nAttaching package: 'data.table'\n\n\nThe following object is masked from 'package:plm':\n\n    between\n\n\nThe following objects are masked from 'package:zoo':\n\n    yearmon, yearqtr\n\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n\n\nAttaching package: 'didimputation'\n\n\nThe following objects are masked from 'package:did2s':\n\n    df_het, df_hom\n\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\nRows: 416 Columns: 12\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(!is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever,\n         expand_year = ifelse(expand_ever==FALSE, 0, expand_year))\n\nmod.bea &lt;- did_imputation(reg.dat, yname=\"perc_unins\", \n                gname=\"expand_year\",\n                tname=\"year\",\n                idname=\"State\",\n                first_stage = ~ 0 | State + year,\n                cluster_var=\"State\",\n                horizon=TRUE,\n                pretrends=-3:-1)"
  },
  {
    "objectID": "slides/class9.html#borusyak-et-al.-in-practice-1",
    "href": "slides/class9.html#borusyak-et-al.-in-practice-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Borusyak et al. in practice",
    "text": "Borusyak et al. in practice\n\n\nR Code\ncoef.bea &lt;- mod.bea %&gt;%\n    select(rel_year = term, estimate, std.error) %&gt;%\n    mutate(\n        ci_lower = estimate - 1.96 * std.error,\n        ci_upper = estimate + 1.96 * std.error,\n        group = \"Borusyak et al Imputation\",\n        rel_year = as.numeric(rel_year)\n    )\n\nggplot(coef.bea) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_vline(xintercept = -0.5, linetype = \"dashed\") +\n    geom_linerange(mapping = aes(x = rel_year, ymin = ci_lower, ymax = ci_upper), color = \"grey30\") +\n    geom_point(mapping = aes(x = rel_year, y = estimate, color = group), size = 2) +\n    scale_x_continuous(breaks = -3:5, minor_breaks = NULL) +\n    scale_y_continuous(minor_breaks = NULL) +\n    labs(x = \"Relative Time\", y = \"Estimate\", color = NULL, title = NULL) +\n  theme_bw() + theme(legend.position=\"none\")"
  },
  {
    "objectID": "slides/class9.html#seems-like-lots-of-solutions",
    "href": "slides/class9.html#seems-like-lots-of-solutions",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Seems like lots of “solutions”",
    "text": "Seems like lots of “solutions”\n\nCallaway and Sant’Anna (2020)\nSun and Abraham (2020)\nde Chaisemartin and D’Haultfoeuille (2020)\nCengiz et al (2019)\nGardner (2021) and Borusyak et al. (2021)\n\n\nGoodman-Bacon (2021) explores the problems but doesn’t really propose a solution (still very important work though!)"
  },
  {
    "objectID": "slides/class9.html#comparison",
    "href": "slides/class9.html#comparison",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Comparison",
    "text": "Comparison\n\n\nR Code\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\nmcaid.data &lt;- read_tsv(\"../files/data/acs/acs_medicaid.txt\")\n\n\nRows: 416 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): State\ndbl  (8): year, adult_pop, ins_employer, ins_direct, ins_medicare, ins_medic...\nlgl  (2): expand_ever, expand\ndate (1): date_adopted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nR Code\nreg.dat &lt;- mcaid.data %&gt;% \n  filter(!is.na(expand_ever)) %&gt;%\n  mutate(perc_unins=uninsured/adult_pop,\n         post = (year&gt;=2014), \n         treat=post*expand_ever,\n         time_to_treat = ifelse(expand_ever==FALSE, 0, year-expand_year),\n         time_to_treat = ifelse(time_to_treat &lt; -3, -3, time_to_treat))\n\nmod.twfe &lt;- feols(perc_unins~i(time_to_treat, expand_ever, ref=-1) | State + year,\n                  cluster=~State,\n                  data=reg.dat)\n\n\ncoef.twfe &lt;- tidy(mod.twfe) %&gt;%\n  mutate(term=str_replace(term,\"time_to_treat::\",\"\"),\n         term=str_replace(term,\":expand_ever\",\"\")) %&gt;%\n  rename(rel_year=term) %&gt;%\n  select(rel_year, estimate, std.error) %&gt;%\n  bind_rows(tibble(rel_year=\"-1\", estimate=0, std.error=0)) %&gt;%  \n  mutate(\n    ci_lower = estimate - 1.96 * std.error,\n    ci_upper = estimate + 1.96 * std.error,\n    group = \"TWFE\",\n    rel_year = as.numeric(rel_year)\n  ) %&gt;%\n  filter(rel_year&gt;=-3, rel_year&lt;=5)\n\ncoef.2s &lt;- tidy(mod.2s) %&gt;%\n  mutate(term=str_replace(term,\"time_to_treat::\",\"\")) %&gt;%\n  rename(rel_year=term) %&gt;%\n  select(rel_year, estimate, std.error) %&gt;%\n  bind_rows(tibble(rel_year=\"-1\", estimate=0, std.error=0)) %&gt;%  \n  mutate(\n    ci_lower = estimate - 1.96 * std.error,\n    ci_upper = estimate + 1.96 * std.error,\n    group = \"Gardner 2SDiD\",\n    rel_year = as.numeric(rel_year)\n  )\n\ncoef.sa &lt;- tidy(mod.sa) %&gt;%\n  mutate(term=str_replace(term,\"time_to_treat::\",\"\")) %&gt;%\n  rename(rel_year=term) %&gt;%\n  select(rel_year, estimate, std.error) %&gt;%\n  bind_rows(tibble(rel_year=\"-1\", estimate=0, std.error=0)) %&gt;%    \n  mutate(\n    ci_lower = estimate - 1.96 * std.error,\n    ci_upper = estimate + 1.96 * std.error,\n    group = \"Sun and Abraham\",\n    rel_year = as.numeric(rel_year)\n  ) %&gt;%\n  filter(rel_year&gt;=-3, rel_year&lt;=5)\n\n\ncoef.cs &lt;- tidy(mod.cs.event) %&gt;%\n  select(rel_year=event.time, estimate, ci_lower=conf.low, ci_upper=conf.high) %&gt;%\n  mutate(rel_year=as.numeric(rel_year),\n         group = \"Callaway and Sant'Anna\") %&gt;%\n  filter(rel_year&gt;=-3, rel_year&lt;=5)\ncoef.cs &lt;- as_tibble(coef.cs)\n\ncoef.all &lt;- bind_rows(coef.twfe, coef.cs, coef.sa, coef.2s, coef.bea) %&gt;%\n  select(rel_year, estimate, ci_lower, ci_upper, group)\n\nggplot(coef.all, aes(x=rel_year, y=estimate)) + \n  geom_point(aes(color=group), size = 2, position=position_dodge(width=0.7))  +\n  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position=position_dodge2(width=0.7)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = -0.5, linetype = \"dashed\") +\n  theme(legend.position=\"bottom\") +\n  guides(color=guide_legend(ncol=2, title=NULL)) +\n  scale_x_continuous(breaks = -3:5, minor_breaks = NULL) +\n  scale_y_continuous(minor_breaks = NULL) +\n  labs(x = \"Relative Time\", y = \"Estimate\", color = NULL, title = NULL)"
  },
  {
    "objectID": "slides/class9.html#comparison-1",
    "href": "slides/class9.html#comparison-1",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Comparison",
    "text": "Comparison\n\n\nSimilarities\n\nFocus on clean treatment/control\nFocus on event study framework (not a single overall effect)\nImpose some form of parallel trends assumption\n\n\nDifferences\n\nIs there a “never treated” group?\nCan treatment turn on and off?\nHow to include covariates?\nHow to do inference?"
  },
  {
    "objectID": "slides/class9.html#general-advice",
    "href": "slides/class9.html#general-advice",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "General advice",
    "text": "General advice\n\nDo you have staggered treatment adoption? If so, will need to consider something beyond TWFE event study (even if it doesn’t change results)\nDo you need time-varying covariates? If so, consider Sun and Abraham or stacked regression (2SDD and imputation can only use pre-treatment covariates). But also, why do you need time-varying covariates?\nIs treatment “strict”? If not, CH is only option right now\nDoes treatment turn on and off again? If so, CH or perhaps focus on “clean” treatment adoptions\nInference? Stacked regression is harder here. (see Wing, Freedman, and Hollingsworth (2024) for recent work on this)"
  },
  {
    "objectID": "slides/class9.html#other-topics",
    "href": "slides/class9.html#other-topics",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "Other topics",
    "text": "Other topics\n\nCan you test for parallel pre-trends?\nRecent work says such tests are underpowered\nConsider potential violations of parallel trends and assess results\n\nIntuitively “easy” to do in manual \\((g,t)\\) or imputation setting, harder in pure regression setting\nSee Rambachan and Roth (2023) and Freyaldenhoven et al. (2021) for recent work on this\nParallel trends sensitive to functional form, see Roth and Sant’Anna (2023)"
  },
  {
    "objectID": "slides/class9.html#the-data",
    "href": "slides/class9.html#the-data",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "1. The Data",
    "text": "1. The Data\n\nHCRIS\nPOS\nKFF Medicaid Expansion"
  },
  {
    "objectID": "slides/class9.html#hcris",
    "href": "slides/class9.html#hcris",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "HCRIS",
    "text": "HCRIS\n\nComprehensive dataset on hospital financials and other details\nChallenging to get information out of these reports\nVery messy with lots of misreporting\nHospitals identified by “Medicare Provider Number” (also known as CMS Certification Number, or CCN) and “NPI”\nWe’ll work with the provider number in this assignment"
  },
  {
    "objectID": "slides/class9.html#pos",
    "href": "slides/class9.html#pos",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "POS",
    "text": "POS\n\n“Cumulative” file listing all Medicare-approved facilities other than clinical labs (those are in separate files)\nDuplicate observations in each year\nClosed hospitals should stay in the data every year, with a termination date filled when closed\nLOTS more facilities than hospitals"
  },
  {
    "objectID": "slides/class9.html#kff-medicaid-expansion",
    "href": "slides/class9.html#kff-medicaid-expansion",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "KFF Medicaid Expansion",
    "text": "KFF Medicaid Expansion\n\nList of states and dates in which Medicaid was implemented"
  },
  {
    "objectID": "slides/class9.html#the-analysis",
    "href": "slides/class9.html#the-analysis",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "2. The analysis",
    "text": "2. The analysis\n\nSummary statistics and figures\nDD, TWFE, Event Studies\nSun and Abraham\nCallaway and Sant’Anna\nCallaway and Sant’Anna with “Honest” pre-trends"
  },
  {
    "objectID": "slides/class9.html#discussion-and-reflection",
    "href": "slides/class9.html#discussion-and-reflection",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "3. Discussion and reflection",
    "text": "3. Discussion and reflection\n\nDiscussion: Looking for overall takeaways here, nothing too formal.\nReflection: Explain something you found surprising. Maybe it was something that you enjoyed learning or implementing. Maybe it was something that you struggled with but that you thought, ex ante, would be easier. Or maybe you were surprised at how awesome you are! Anything goes really…just be genuine."
  },
  {
    "objectID": "slides/class9.html#expectations",
    "href": "slides/class9.html#expectations",
    "title": "A Quick Primer on Diff-in-Diff",
    "section": "4. Expectations",
    "text": "4. Expectations\n\nPDF should be more like a report than a research notebook (code goes in the repo, not in the report)\nSeparate your analysis from your writing (perhaps by cleaning and then saving your workspace, and importing it into your markdown doc)\nTables and Figures should be near-publication quality, with clean and clear variable names, axes, labels, etc.\nSpend time on good workflow and professional looking products…you can re-use all of this code and workflow for the rest of your career!"
  },
  {
    "objectID": "assignments/index.html",
    "href": "assignments/index.html",
    "title": "Assignments",
    "section": "",
    "text": "Below are basic descriptions of each category of assignments for this semester. More details are available on the individual pages for each assignment.",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#research-proposals",
    "href": "assignments/index.html#research-proposals",
    "title": "Assignments",
    "section": "Research Proposals",
    "text": "Research Proposals\nYou’ll submit three proposals thoughout the semester. Each proposal should consist of four parts, explained in more detail here, and is worth 10 points toward your final grade. The written proposal should be 2 pages, double-spaced, 12-point font, and 1-inch margins.\nThink of the research proposal as a more informed version of brainstorming. This should be something for which you’ve given some serious thought but where you haven’t yet started any analysis. You at least have some idea of the data you’d like to use, where to find it, and how to use it (i.e., you have some identification strategy and estimation method in mind). The purpose of the proposal is to develop and idea sufficiently far before receiving feedback.",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#research-plans",
    "href": "assignments/index.html#research-plans",
    "title": "Assignments",
    "section": "Research Plans",
    "text": "Research Plans\nYour research plan consists of five parts, explained in more detail here. This is an extension of the research proposal where you consider the value-added of your work relative to the existing literature. Essentially, the research plan is your research proposal plus a literature review. You should take your best research proposal, based on feedback from me (and possibly your peers and classmates), and develop a slightly longer three-page report (double-spaced, 12-point font, 1-inch margins).\nThe research plan is worth 10 points toward your final grade (2 points per section of the report). It is due via Canvas by April 21. You will also need to develop a short 15 minute presentation for your proposal. We’ll spend the final two class days discussing your research plans and how best to turn them into papers!",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#paper-presentations",
    "href": "assignments/index.html#paper-presentations",
    "title": "Assignments",
    "section": "Paper Presentations",
    "text": "Paper Presentations\nYou will present four academic papers throughout the course of the semester. The list of potential papers for any given day is on the class schedule, with additional details here. Please note your selected papers and class dates on the Presentations tab of our shared Google Sheet (link availabel on Canvas) no later than January 20. Each presentation is worth 5 points toward your final grade.",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#empirical-exercises",
    "href": "assignments/index.html#empirical-exercises",
    "title": "Assignments",
    "section": "Empirical Exercises",
    "text": "Empirical Exercises\nThere are four prepared empirical exercises. Three of the excercises focus on central causal inference strategies (difference-in-differences, instrumental variables, or regression discontinuity), and the fourth exercise considers the analysis of competition in healthcare, including demand estimation. You must select one exercise to complete throughout the semester no later than January 29, and note your selection on the Exercises tab of our shared Google Sheet. No more than two students per exercise.\nEach exercise requires a good amount of your time outside of class to get the data in working order and implement the relevant identification strategy and econometric estimator. Raw data for each exercise will be provided on our class OneDrive folder, the link to which is on Canvas, or via the paper’s online replication package. For more details on each exercise and on the requirements for submission, see here.",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#excellence-blueprint",
    "href": "assignments/index.html#excellence-blueprint",
    "title": "Assignments",
    "section": "“Excellence” Blueprint",
    "text": "“Excellence” Blueprint\nThe objective of this assignment is to move beyond critiquing flaws and instead develop an appreciation for very high quality academic writing and research execution. You will analyze a recently published, high-impact health economics paper, dissecting not only its substantive contribution and rigor but also the writing, narrative, and presentation that secured its placement in a top-tier journal. Your final blueprint is due on March 17, and details of this assignment are available here.",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/excellence-blueprint.html",
    "href": "assignments/excellence-blueprint.html",
    "title": "Excellence Blueprint",
    "section": "",
    "text": "Your analysis must answer the core question: What specific choices, in both research design and articulation, warrant this paper’s strong publication and reputation? In answering this question, please divide your report into two sections (10 points for each section):\n\nThe Science: Address the paper’s substance and fit within the literature. This section should detail what the paper contributes and how its methods stand up to scrutiny.\n\nNovelty and Contribution: Clearly articulate the paper’s central research question. What specific gap in the literature does it fill? What is the single most important new insight this work provides to the field of health economics?\nMethodological Excellence: Analyze the core empirical strategy. What choices (e.g., data selection, identification strategy, or estimator) demonstrate methodological rigor? Why is the chosen method appropriate in this case?\nEngagement with Literature: Assess how the authors position their work. Identify two key papers the authors successfully build upon or challenge, and explain how the introduction and discussion sections integrate the new findings into the existing scholarly conversation.\n\nThe Art: Analyze the paper’s execution and its persuasive power. This section should detail how the authors guide the reader and present their findings clearly.\n\nIntroduction and Hook: Dissect the first two pages. How does the paper successfully motivate the question and establish its importance to both academics and policymakers? Pinpoint two specific sentences or paragraphs that are highly effective in hooking the reader and explain why they work.\nClarity and Structure: Evaluate the overall narrative flow. How do the authors simplify and present complex econometric analyses? Identify specific structural elements (e.g., headings, figures, tables) that enhance clarity and guide the reader through the evidence without sacrificing technical precision.\nThe Policy Takeaway: Analyze the conclusion and/or discussion sections. How do the authors move from specific empirical findings to a broader, impactful policy implication? Explain how the discussion ensures the paper’s findings are memorable and actionable.\n\n\nYour final product should be no longer than 4 pages (double-spaced, 11 point font, 1 inch margins), not including a bibliography."
  },
  {
    "objectID": "schedule/1-0.html",
    "href": "schedule/1-0.html",
    "title": "Demand for Health Insurance",
    "section": "",
    "text": "A large literature studies demand for health insurance by examining how individuals respond to coverage and how they make insurance choices under uncertainty. Experimental evidence from the RAND Health Insurance Experiment established that insurance generosity substantially affects healthcare utilization, providing early causal evidence on moral hazard and the role of cost sharing in shaping demand (Aron-Dine, Einav, and Finkelstein (2013)). More recent experimental work from the Oregon Medicaid lottery confirms that gaining insurance coverage increases utilization and improves financial security, with more nuanced effects on health outcomes (Finkelstein et al. (2012)). Together, these studies show that insurance coverage meaningfully changes behavior, while also highlighting that observed demand reflects both preferences and the structure of insurance contracts. While moral hazard and utilization responses are central to understanding insurance demand, these mechanisms are well covered elsewhere (see Einav and Finkelstein (2018) for a comprehensive treatment) and are not the primary focus here.\nBeyond responses to coverage, a growing body of work documents systematic frictions in health insurance choice. Individuals frequently select plans that are dominated given their realized healthcare needs, suggesting that limited attention, complexity, and misperceptions play an important role in insurance demand (Abaluck and Gruber (2011); Jonathan D. Ketcham et al. (2012); Jonathan D. Ketcham, Kuminoff, and Powers (2016); Abaluck and Gruber (2016)). This evidence has motivated recent research on whether low-cost policy interventions can improve insurance choices when decision-making is distorted by costly cognition. For example, default plan assignments in public drug insurance settings have been shown to strongly influence enrollment and utilization, with important implications for welfare and market design (Brot-Goldberg et al. (2023)).\nPotential papers for presentation today include:\n\nAron-Dine, Einav, and Finkelstein (2013) — RAND Health Insurance Experiment and utilization responses\nFinkelstein et al. (2012) — Oregon Medicaid lottery and the effects of insurance coverage\nBrot-Goldberg et al. (2023) — defaults, costly cognition, and insurance choice\n\n\n\n\n\nReferences\n\nAbaluck, Jason, and Jonathan Gruber. 2011. “Choice Inconsistencies Among the Elderly: Evidence from Plan Choice in the Medicare Part D Program.” American Economic Review 101 (4): 1180–210. https://doi.org/10.1257/aer.101.4.1180.\n\n\n———. 2016. “Choice Inconsistencies Among the Elderly: Evidence from Plan Choice in the Medicare Part D Program: Reply.” American Economic Review 106 (12): 3962–87. https://doi.org/10.1257/aer.20151318.\n\n\nAron-Dine, Aviva, Liran Einav, and Amy Finkelstein. 2013. “The RAND Health Insurance Experiment, Three Decades Later.” Journal of Economic Perspectives 27 (1): 197–222.\n\n\nBrot-Goldberg, Zarek, Timothy Layton, Boris Vabson, and Adelina Yanyue Wang. 2023. “The Behavioral Foundations of Default Effects: Theory and Evidence from Medicare Part D.” American Economic Review 113 (10): 2718–58. https://doi.org/10.1257/aer.20210013.\n\n\nEinav, Liran, and Amy Finkelstein. 2018. “Moral Hazard in Health Insurance: What We Know and How We Know It.” Journal of the European Economic Association 16 (4): 957–82. https://doi.org/10.1093/jeea/jvy017.\n\n\nFinkelstein, Amy, Sarah Taubman, Bill Wright, Mira Bernstein, Jonathan Gruber, Joseph P Newhouse, Heidi Allen, Katherine Baicker, et al. 2012. “The Oregon Health Insurance Experiment: Evidence from the First Year.” Quarterly Journal of Economics 127 (3): 1057–1106.\n\n\nKetcham, Jonathan D., Nicolai V. Kuminoff, and Christopher A. Powers. 2016. “Choice Inconsistencies Among the Elderly: Evidence from Plan Choice in the Medicare Part D Program: Comment.” American Economic Review 106 (12): 3932–61. https://doi.org/10.1257/aer.20131048.\n\n\nKetcham, Jonathan D, Claudio Lucarelli, Eugenio J Miravete, and M Christopher Roebuck. 2012. “Sinking, Swimming, or Learning to Swim in Medicare Part D.” American Economic Review 102 (6): 2639–73."
  },
  {
    "objectID": "schedule/1-0.html#papers-for-presentation",
    "href": "schedule/1-0.html#papers-for-presentation",
    "title": "Demand for Health Insurance",
    "section": "Papers for presentation",
    "text": "Papers for presentation\nPotential papers for presentation today include:\n\nAron-Dine, Einav, and Finkelstein (2013) — RAND Health Insurance Experiment and utilization responses\nFinkelstein et al. (2012) — Oregon Medicaid lottery and the effects of insurance coverage\nBrot-Goldberg et al. (2023) — defaults, costly cognition, and insurance choice"
  },
  {
    "objectID": "schedule/1-literature.html",
    "href": "schedule/1-literature.html",
    "title": "Health Insurance",
    "section": "",
    "text": "Module 1 covers health insurance markets. We begin with demand for health insurance and the welfare consequences of coverage, establishing how risk, prices, and moral hazard shape utilization and consumer welfare. We then study adverse selection as a central friction in insurance markets, before turning to insurer competition and market structure. The module concludes with public insurance design, emphasizing how government programs interact with private markets and how policy design affects incentives, enrollment, and efficiency. The topic of “health insurance” is extremely broad, but nonetheless, here’s a long list of papers that I think are particularly relevant in this area.\n\n    List of Key Papers (click to expand)"
  },
  {
    "objectID": "schedule/index.html",
    "href": "schedule/index.html",
    "title": "Schedule",
    "section": "",
    "text": "Below is a breakdown of topics for each class day this semester. Assignments are also listed according to their due dates. The associated links take you to additional information relevant for that day or for that assignment. Each heading is also linked to a broader literature review for that topic, containing many more papers than we will cover in class. For those of you interested in learning more about a particular topic, this is a good place to start."
  },
  {
    "objectID": "schedule/index.html#welcome-to-the-class",
    "href": "schedule/index.html#welcome-to-the-class",
    "title": "Schedule",
    "section": "Welcome to the class!",
    "text": "Welcome to the class!\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n1\n1/13\nIntroductions"
  },
  {
    "objectID": "schedule/index.html#module-1-health-insurance-and-market-design",
    "href": "schedule/index.html#module-1-health-insurance-and-market-design",
    "title": "Schedule",
    "section": "Module 1: Health Insurance and Market Design",
    "text": "Module 1: Health Insurance and Market Design\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n2\n1/15\nDemand for Health Insurance\n\n\n\n\n1/16\nSelect Papers to Present\n\n\n\n3\n1/20\nWelfare Effects of Health Insurance\n\n\n\n4\n1/22\nAdverse Selection\n\n\n\n5\n1/27\nCompetition and Market Structure\n\n\n\n6\n1/29\nPublic Insurance Design\n\n\n\n\n\nSelect Empirical Exercise"
  },
  {
    "objectID": "schedule/index.html#module-2-physician-agency-and-treatment-decisions",
    "href": "schedule/index.html#module-2-physician-agency-and-treatment-decisions",
    "title": "Schedule",
    "section": "Module 2: Physician Agency and Treatment Decisions",
    "text": "Module 2: Physician Agency and Treatment Decisions\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n7\n2/3\nPhysician Agency\n\n\n\n8\n2/5\nFinancial Incentives\n\n\n\n\n\nResearch Proposal 1 Due\n\n\n\n9\n2/10\nNon-financial Incentives\n\n\n\n10\n2/12\nAgency in Organizations and Teams"
  },
  {
    "objectID": "schedule/index.html#module-3-physician-learning-and-technology-adoption",
    "href": "schedule/index.html#module-3-physician-learning-and-technology-adoption",
    "title": "Schedule",
    "section": "Module 3: Physician Learning and Technology Adoption",
    "text": "Module 3: Physician Learning and Technology Adoption\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n11\n2/17\nLearning under Uncertainty\n\n\n\n12\n2/19\nSkill Accumulation\n\n\n\n13\n2/24\nPatient-Treatment Match Value\n\n\n\n14\n2/26\nLearning from Others\n\n\n\n\n\nResearch Proposal 2 Due"
  },
  {
    "objectID": "schedule/index.html#module-4-hospital-competition-and-pricing",
    "href": "schedule/index.html#module-4-hospital-competition-and-pricing",
    "title": "Schedule",
    "section": "Module 4: Hospital Competition and Pricing",
    "text": "Module 4: Hospital Competition and Pricing\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n15\n3/3\nUnderstanding Hospital Competition\n\n\n\n16\n3/5\nCompetition in Reduced Form\n\n\n\n17\n3/17\nBargaining and Hospital Pricing\n\n\n\n18\n3/19\nCross-market Mergers\n\n\n\n19\n3/24\nVertical Integration"
  },
  {
    "objectID": "schedule/index.html#module-5-information-disclosure-and-transparency",
    "href": "schedule/index.html#module-5-information-disclosure-and-transparency",
    "title": "Schedule",
    "section": "Module 5: Information Disclosure and Transparency",
    "text": "Module 5: Information Disclosure and Transparency\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n20\n3/26\nBasics of Information Disclosure\n\n\n\n\n\nResearch Proposal 3 Due\n\n\n\n21\n3/31\nPhysician Quality\n\n\n\n22\n4/2\nInsurance Ratings\n\n\n\n23\n4/7\nPrice Transparency"
  },
  {
    "objectID": "schedule/index.html#module-6-recent-job-market-papers",
    "href": "schedule/index.html#module-6-recent-job-market-papers",
    "title": "Schedule",
    "section": "Module 6: Recent Job Market Papers",
    "text": "Module 6: Recent Job Market Papers\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n24\n4/9\nJMPs from 2023\n\n\n\n25\n4/14\nJMPs from 2024\n\n\n\n26\n4/16\nJMPs from 2025"
  },
  {
    "objectID": "schedule/index.html#final-research-plans",
    "href": "schedule/index.html#final-research-plans",
    "title": "Schedule",
    "section": "Final Research Plans",
    "text": "Final Research Plans\n\n\n\n\n\n\n\n\n\nClass\nDates\nTopic\nDescription\n\n\n\n\n27\n4/21\nResearch Plans\n\n\n\n28\n4/23\nResearch Plans\n\n\n\n\n\nEmpirical Exercise Due"
  },
  {
    "objectID": "schedule/0-0.html",
    "href": "schedule/0-0.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to the course! Today we’ll spend some time talking about the structure of the class, the assignments, grading, etc. We’ll also navigate the website for a bit just to make sure we can get around and understand where different information is. But the main goal for today is just to get to know each other and our collective research interests."
  },
  {
    "objectID": "assignments/empirical-exercises.html",
    "href": "assignments/empirical-exercises.html",
    "title": "Empirical Exercises",
    "section": "",
    "text": "You must choose one of four empirical exercises to complete this semester. The exercises are listed and described in more detail below (or on our class website):\n\nExercise 1: Difference-in-differences\nExercise 2: Instrumental variables\nExercise 3: Regression Discontinuity\nExercise 4: Hospital markets + demand estimation\n\nPlease note which exercise you plan to complete on our shared Google Sheet by January 29 and submit your final assignment as a GitHub repository link by April 23. The exercise is worth 20 points toward your final grade, 2 points for each of 10 questions.\nIn your repository, please include a final PDF file, along with all of your supporting documentation, including your code files (Stata, R, Python, SAS, etc.), all figures/tables, and some instructions (e.g., as part of your ReadMe file) that introduce the reader to your data and the sequence in which your code should be run. Practice writing good code and showing me only what I would need to recreate your results. Please also be sure to organize your folders in a useful way (e.g., clearly organized subdirectories such as “data”, “data-code”, “analysis”, “results”, etc.). It’s good to start developing some organization practices that work best for you as early as possible. It’s extremely easy to forget what you were doing on a project once you have several things going at once, especially when you wait for 6-8 months after submitting a paper for publication. The last thing you want is to not be able to replicate your own work!",
    "crumbs": [
      "Assignments",
      "Empirical Exercises"
    ]
  },
  {
    "objectID": "assignments/presentations.html",
    "href": "assignments/presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Please review the class schedule and select four papers from the list of topics in each class, excluding any “background” classes. Your selections must also be on different dates. Once you’ve identified your papers, note your paper(s) title, authors, your name, and the date of your presentation on the Presentations tab of our shared Google Sheet (available on Canvas). Please note your selections no later than January 16.\nWe will focus on one paper per class day, so you should prepare for a 60 minute presentation. Please follow a standard seminar setup. Please also prepare two discussion questions to lead a 10-15 minute discussion after your presentation. Please submit your presentations via Canvas prior to your in-class submisson.\nYour presentation should be no more than 50 slides (including a title slide and your discussion questions at the end). Each presentation is worth 5 points toward your final grade, with one point allocated to each of the following categories:\nNote that a presentation is not just a re-hashing of the paper in slide form. A good academic presentation should have as little information as possible on each slide, and the content on the slides doesn’t necessarily need to follow that of the paper. For example, in a real-time environment, it is much easier to move between different aspects of the empirical analysis and data. Below are lists of candidate papers for presentation for each module. These are also listed in the shared spreadsheet (on Canvas) from which you can formally indicate your selections.",
    "crumbs": [
      "Assignments",
      "Presentations"
    ]
  },
  {
    "objectID": "schedule/1-1.html",
    "href": "schedule/1-1.html",
    "title": "Welfare Effects of Health Insurance",
    "section": "",
    "text": "Today, we move on from why people buy health insurance to the effects of health insurance, with particular attention to financial well-being, health, and broader welfare implications. One strand of this literature focuses on the financial effects of health insurance. By reducing exposure to medical expenditures, insurance can relax household budget constraints and lower the likelihood of financial distress. Empirical evidence exploiting Medicaid expansions shows that gaining public insurance reduces adverse financial outcomes such as medical debt and bankruptcy, highlighting an important channel through which insurance affects economic well-being beyond healthcare consumption (Gross and Notowidigdo (2011); Hu et al. (2018)).\nA second strand examines the health effects of insurance coverage. While it is not theoretically obvious that insurance must improve health, recent work using large administrative datasets and quasi-experimental designs provides compelling evidence that expanded coverage improves health outcomes and reduces mortality. These studies reflect a shift in the literature toward settings and data that are sufficiently powered to detect health effects over longer horizons (Miller, Johnson, and Wherry (2021); Goldin, Lurie, and McCubbin (2021)).\nFinally, a broader literature considers the overall welfare effects of health insurance, emphasizing that insurance policies generate indirect effects that extend beyond the insured population. The introduction and expansion of public insurance programs can affect provider behavior, healthcare spending, and the allocation of resources across the economy. Classic and recent work shows that large-scale insurance expansions such as Medicare and Medicaid have substantial general equilibrium and fiscal implications, underscoring the importance of evaluating insurance policies from a system-wide perspective rather than focusing solely on individual beneficiaries (Finkelstein (2007); Finkelstein, Hendren, and Luttmer (2019)).\nPotential papers for presentation today include\n\nHu et al. (2018) — financial protection and household debt under Medicaid\nMiller, Johnson, and Wherry (2021) — health and mortality effects of insurance coverage\nFinkelstein, Hendren, and Luttmer (2019) — welfare valuation of Medicaid incorporating transfers and external effects\n\n\n\n\n\nReferences\n\nFinkelstein, Amy. 2007. “The Aggregate Effects of Health Insurance: Evidence from the Introduction of Medicare.” The Quarterly Journal of Economics 122 (1): 1–37. https://doi.org/10.1162/qjec.122.1.1.\n\n\nFinkelstein, Amy, Nathaniel Hendren, and Erzo F. P. Luttmer. 2019. “The Value of Medicaid: Interpreting Results from the Oregon Health Insurance Experiment.” Journal of Political Economy 127 (6): 2836–74. https://doi.org/10.1086/702238.\n\n\nGoldin, Jacob, Ithai Z Lurie, and Janet McCubbin. 2021. “Health Insurance and Mortality: Experimental Evidence from Taxpayer Outreach.” The Quarterly Journal of Economics 136 (1): 1–49. https://doi.org/10.1093/qje/qjaa029.\n\n\nGross, Tal, and Matthew J. Notowidigdo. 2011. “Health Insurance and the Consumer Bankruptcy Decision: Evidence from Expansions of Medicaid.” Journal of Public Economics 95 (7): 767–78. https://doi.org/10.1016/j.jpubeco.2011.01.012.\n\n\nHu, Luojia, Robert Kaestner, Bhashkar Mazumder, Sarah Miller, and Ashley Wong. 2018. “The Effect of the Affordable Care Act Medicaid Expansions on Financial Wellbeing.” Journal of Public Economics 163 (July): 99–112. https://doi.org/10.1016/j.jpubeco.2018.04.009.\n\n\nMiller, Sarah, Norman Johnson, and Laura R Wherry. 2021. “Medicaid and Mortality: New Evidence From Linked Survey and Administrative Data.” The Quarterly Journal of Economics 136 (3): 1783–1829. https://doi.org/10.1093/qje/qjab004."
  },
  {
    "objectID": "schedule/1-5.html",
    "href": "schedule/1-5.html",
    "title": "Public Insurance Design",
    "section": "",
    "text": "Public insurance programs in the U.S. increasingly rely on private insurers to deliver coverage, most notably through Medicare Advantage and Medicaid managed care. These programs are built around the idea of managed competition, in which insurers compete for enrollees under regulated payment, subsidy, and risk-adjustment schemes. A central question in this literature is whether competition in these settings benefits consumers or instead generates rents for insurers, depending on how program rules are designed.\nOne strand of this literature studies subsidy design, pass-through, and insurer incentives in public insurance markets. Empirical evidence from Medicare Advantage shows that poorly designed subsidies may be incompletely passed through to consumers, leading to higher insurer profits rather than lower premiums. These papers highlight the importance of benchmark rules, bidding incentives, and regulatory constraints in shaping equilibrium outcomes (Cabral, Geruso, and Mahoney (2018); V. Curto et al. (2021)).\nA related strand examines public versus private provision of health insurance, reflecting growing interest in the consequences of privatization within public programs. As enrollment in Medicaid managed care and Medicare Advantage has expanded, researchers have studied how private provision affects costs, access, and consumer outcomes relative to traditional public insurance. This work emphasizes tradeoffs between efficiency, selection, and administrative complexity, and remains an active area of research (Layton et al. (2019); Macambira et al. (2022)).\nFinally, recent work explores new directions in expanding access and affordability in health insurance markets, often motivated by ongoing policy debates. These papers evaluate reforms aimed at improving coverage and affordability, with a focus on welfare implications and distributional effects, and highlight open questions about how best to design insurance systems that balance access, cost, and efficiency (Geddes and Schnell (2023); V. E. Curto (2023)).\nPotential papers for presentation today include\n\nCabral, Geruso, and Mahoney (2018) — subsidies, pass-through, and insurer incentives in Medicare Advantage\nV. Curto et al. (2021) — competition and consumer outcomes in regulated insurance markets\nLayton et al. (2019) — public versus private provision in health insurance\nGeddes and Schnell (2023) or V. E. Curto (2023) — expanding access and affordability (frontier work)\n\n\n\n\n\nReferences\n\nCabral, Marika, Michael Geruso, and Neale Mahoney. 2018. “Do Larger Health Insurance Subsidies Benefit Patients or Producers? Evidence from Medicare Advantage.” American Economic Review 108 (8): 2048–87.\n\n\nCurto, Vilsa E. 2023. “Pricing Regulations in Individual Health Insurance: Evidence from Medigap.” Journal of Health Economics 91 (September): 102785. https://doi.org/10.1016/j.jhealeco.2023.102785.\n\n\nCurto, Vilsa, Liran Einav, Jonathan Levin, and Jay Bhattacharya. 2021. “Can Health Insurance Competition Work? Evidence from Medicare Advantage.” Journal of Political Economy 129 (2): 570–606.\n\n\nGeddes, Eilidh, and Molly Schnell. 2023. “The Expansionary and Contractionary Supply-Side Effects of Health Insurance.” Working {Paper}. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w31483.\n\n\nLayton, Timothy J., Nicole Maestas, Daniel Prinz, and Boris Vabson. 2019. “Private Vs. Public Provision of Social Insurance: Evidence from Medicaid.” Working {Paper}. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w26042.\n\n\nMacambira, Danil Agafiev, Michael Geruso, Anthony Lollo, Chima D. Ndumele, and Jacob Wallace. 2022. “The Private Provision of Public Services: Evidence from Random Assignment in Medicaid.” w30390. National Bureau of Economic Research. https://doi.org/10.3386/w30390."
  },
  {
    "objectID": "schedule/1-3.html",
    "href": "schedule/1-3.html",
    "title": "Adverse Selection",
    "section": "",
    "text": "Great — this is a strong starting point. I’ll keep your structure and intent, but tighten it to match the tone and format you settled on for the earlier days:\nI’ll also flag where I’d narrow choices, as you asked earlier."
  },
  {
    "objectID": "schedule/1-3.html#adverse-selection",
    "href": "schedule/1-3.html#adverse-selection",
    "title": "Adverse Selection",
    "section": "Adverse Selection",
    "text": "Adverse Selection\nA central friction in health insurance markets is adverse selection, which arises when consumers with different expected healthcare costs sort into different insurance plans. When higher-risk individuals disproportionately enroll in more generous coverage, insurers may face average costs that exceed premiums, leading to premium increases, market unraveling, or the withdrawal of plans altogether. A large literature studies how adverse selection affects pricing, plan offerings, and equilibrium outcomes in health insurance markets, as well as how institutional features and policy interventions can mitigate or exacerbate these forces.\nOne strand of this literature focuses on pricing and the empirical detection of adverse selection. These papers develop and apply empirical tools to test for selection by examining the relationship between premiums, plan characteristics, and realized costs. Early and influential work shows how pricing patterns and enrollment responses can reveal the presence and magnitude of adverse selection in real-world insurance markets, providing a foundation for much of the modern empirical literature (Bundorf, Levin, and Mahoney (2012); Einav, Finkelstein, and Cullen (2010)).\nA second strand examines policy interventions aimed at mitigating adverse selection, such as mandates, subsidies, and choice architecture. This work emphasizes that while such policies can improve market stability, they may also generate unintended consequences depending on how consumers respond and how insurers adjust plan design. A series of papers demonstrates that the effectiveness of these interventions depends critically on consumer inertia, switching costs, and the interaction between policy design and market structure (B. R. Handel (2013); B. Handel, Hendel, and Whinston (2015); B. R. Handel, Kolstad, and Spinnewijn (2019)).\nMore recent work extends the analysis of adverse selection beyond premiums and benefits to consider insurance networks as a margin of selection. In this view, plan networks—particularly hospital networks—shape both consumer choice and insurer costs, introducing new channels through which adverse selection operates. Evidence from health insurance exchanges shows that network design can be used strategically to attract or deter certain types of enrollees, linking adverse selection to competition among providers and insurers in novel ways (Shepard (2022)).\nPotential papers for presentation today include\n\nEinav, Finkelstein, and Cullen (2010) — empirical tests for selection using pricing and cost data\nB. R. Handel, Kolstad, and Spinnewijn (2019) — consumer inertia, policy interventions, and adverse selection\nShepard (2022) — hospital networks as a channel for adverse selection"
  },
  {
    "objectID": "schedule/1-2.html",
    "href": "schedule/1-2.html",
    "title": "Adverse Selection",
    "section": "",
    "text": "A central friction in health insurance markets is adverse selection, which arises when consumers with different expected healthcare costs sort into different insurance plans. When higher-risk individuals disproportionately enroll in more generous coverage, insurers may face average costs that exceed premiums, leading to premium increases, market unraveling, or the withdrawal of plans altogether. A large literature studies how adverse selection affects pricing, plan offerings, and equilibrium outcomes in health insurance markets, as well as how institutional features and policy interventions can mitigate or exacerbate these forces.\nOne strand of this literature focuses on pricing and the empirical detection of adverse selection. These papers develop and apply empirical tools to test for selection by examining the relationship between premiums, plan characteristics, and realized costs. Early and influential work shows how pricing patterns and enrollment responses can reveal the presence and magnitude of adverse selection in real-world insurance markets, providing a foundation for much of the modern empirical literature (Bundorf, Levin, and Mahoney (2012); Einav, Finkelstein, and Cullen (2010)).\nA second strand examines policy interventions aimed at mitigating adverse selection, such as mandates, subsidies, and choice architecture. This work emphasizes that while such policies can improve market stability, they may also generate unintended consequences depending on how consumers respond and how insurers adjust plan design. A series of papers demonstrates that the effectiveness of these interventions depends critically on consumer inertia, switching costs, and the interaction between policy design and market structure (B. R. Handel (2013); B. Handel, Hendel, and Whinston (2015); B. R. Handel, Kolstad, and Spinnewijn (2019)).\nMore recent work extends the analysis of adverse selection beyond premiums and benefits to consider insurance networks as a margin of selection. In this view, plan networks—particularly hospital networks—shape both consumer choice and insurer costs, introducing new channels through which adverse selection operates. Evidence from health insurance exchanges shows that network design can be used strategically to attract or deter certain types of enrollees, linking adverse selection to competition among providers and insurers in novel ways (Shepard (2022)).\nPotential papers for presentation today include\n\nEinav, Finkelstein, and Cullen (2010) — empirical tests for selection using pricing and cost data\nB. R. Handel, Kolstad, and Spinnewijn (2019) — consumer inertia, policy interventions, and adverse selection\nShepard (2022) — hospital networks as a channel for adverse selection\n\n\n\n\n\nReferences\n\nBundorf, M Kate, Jonathan Levin, and Neale Mahoney. 2012. “Pricing and Welfare in Health Plan Choice.” American Economic Review 102 (7): 3214–48.\n\n\nEinav, Liran, Amy Finkelstein, and Mark R. Cullen. 2010. “Estimating Welfare in Insurance Markets Using Variation in Prices.” The Quarterly Journal of Economics 125 (3): 877–921. https://doi.org/10.1162/qjec.2010.125.3.877.\n\n\nHandel, Ben, Igal Hendel, and Michael D. Whinston. 2015. “Equilibria in Health Exchanges: Adverse Selection Versus Reclassification Risk.” Econometrica 83 (4): 1261–1313. https://doi.org/10.3982/ECTA12480.\n\n\nHandel, Benjamin R. 2013. “Adverse Selection and Inertia in Health Insurance Markets: When Nudging Hurts.” American Economic Review 103 (7): 2643–82. https://doi.org/10.1257/aer.103.7.2643.\n\n\nHandel, Benjamin R., Jonathan T. Kolstad, and Johannes Spinnewijn. 2019. “Information Frictions and Adverse Selection: Policy Interventions in Health Insurance Markets.” Review of Economics and Statistics 101 (2): 326–40.\n\n\nShepard, Mark. 2022. “Hospital Network Competition and Adverse Selection: Evidence from the Massachusetts Health Insurance Exchange.” American Economic Review 112 (2): 578–615. https://doi.org/10.1257/aer.20201453."
  },
  {
    "objectID": "schedule/1-4.html",
    "href": "schedule/1-4.html",
    "title": "Public Insurance Design",
    "section": "",
    "text": "Public insurance programs in the U.S. increasingly rely on private insurers to deliver coverage, most notably through Medicare Advantage and Medicaid managed care. These programs are built around the idea of managed competition, in which insurers compete for enrollees under regulated payment, subsidy, and risk-adjustment schemes. A central question in this literature is whether competition in these settings benefits consumers or instead generates rents for insurers, depending on how program rules are designed.\nOne strand of this literature studies subsidy design, pass-through, and insurer incentives in public insurance markets. Empirical evidence from Medicare Advantage shows that poorly designed subsidies may be incompletely passed through to consumers, leading to higher insurer profits rather than lower premiums. These papers highlight the importance of benchmark rules, bidding incentives, and regulatory constraints in shaping equilibrium outcomes (Cabral, Geruso, and Mahoney (2018); V. Curto et al. (2021)).\nA related strand examines public versus private provision of health insurance, reflecting growing interest in the consequences of privatization within public programs. As enrollment in Medicaid managed care and Medicare Advantage has expanded, researchers have studied how private provision affects costs, access, and consumer outcomes relative to traditional public insurance. This work emphasizes tradeoffs between efficiency, selection, and administrative complexity, and remains an active area of research (Layton et al. (2019); Macambira et al. (2022)).\nFinally, recent work explores new directions in expanding access and affordability in health insurance markets, often motivated by ongoing policy debates. These papers evaluate reforms aimed at improving coverage and affordability, with a focus on welfare implications and distributional effects, and highlight open questions about how best to design insurance systems that balance access, cost, and efficiency (Geddes and Schnell (2023); V. E. Curto (2023)).\nPotential papers for presentation today include\n\nCabral, Geruso, and Mahoney (2018) — subsidies, pass-through, and insurer incentives in Medicare Advantage\nV. Curto et al. (2021) — competition and consumer outcomes in regulated insurance markets\nLayton et al. (2019) — public versus private provision in health insurance\nGeddes and Schnell (2023) or V. E. Curto (2023) — expanding access and affordability\n\n\n\n\n\nReferences\n\nCabral, Marika, Michael Geruso, and Neale Mahoney. 2018. “Do Larger Health Insurance Subsidies Benefit Patients or Producers? Evidence from Medicare Advantage.” American Economic Review 108 (8): 2048–87.\n\n\nCurto, Vilsa E. 2023. “Pricing Regulations in Individual Health Insurance: Evidence from Medigap.” Journal of Health Economics 91 (September): 102785. https://doi.org/10.1016/j.jhealeco.2023.102785.\n\n\nCurto, Vilsa, Liran Einav, Jonathan Levin, and Jay Bhattacharya. 2021. “Can Health Insurance Competition Work? Evidence from Medicare Advantage.” Journal of Political Economy 129 (2): 570–606.\n\n\nGeddes, Eilidh, and Molly Schnell. 2023. “The Expansionary and Contractionary Supply-Side Effects of Health Insurance.” Working {Paper}. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w31483.\n\n\nLayton, Timothy J., Nicole Maestas, Daniel Prinz, and Boris Vabson. 2019. “Private Vs. Public Provision of Social Insurance: Evidence from Medicaid.” Working {Paper}. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w26042.\n\n\nMacambira, Danil Agafiev, Michael Geruso, Anthony Lollo, Chima D. Ndumele, and Jacob Wallace. 2022. “The Private Provision of Public Services: Evidence from Random Assignment in Medicaid.” w30390. National Bureau of Economic Research. https://doi.org/10.3386/w30390."
  },
  {
    "objectID": "schedule/2-literature.html",
    "href": "schedule/2-literature.html",
    "title": "Healthcare Variation and Physician Agency",
    "section": "",
    "text": "In this module, we study how physicians make treatment decisions in environments characterized by asymmetric information, discretion, and multiple, sometimes conflicting objectives. We begin by introducing physician agency as a central organizing framework for understanding medical decision-making, and then examine how both financial and non-financial incentives shape physician behavior. We conclude by moving beyond the individual physician to consider how treatment decisions are influenced by organizational structure and team-based care, highlighting how agency operates within groups, hospitals, and integrated delivery systems. Here’s a long list of papers that I think are particularly relevant in this area.\n\n    List of Key Papers (click to expand)"
  },
  {
    "objectID": "schedule/2-3.html",
    "href": "schedule/2-3.html",
    "title": "Agency in Organization and Teams",
    "section": "",
    "text": "Much of the research on physician agency focuses on individual decision-making, holding organizational context fixed. In practice, however, physicians rarely operate in isolation. Treatment decisions are shaped by referral networks, team-based care, and organizational constraints imposed by hospitals, physician groups, and integrated delivery systems. Today, we study how physician agency operates when decision-making authority is shared across multiple providers and embedded within organizations.\nReferral networks and team structure play an important role in shaping care delivery. Patterns of interaction among physicians influence treatment intensity, coordination, and patient outcomes, even when financial incentives are held constant. Empirical studies show that referral relationships affect both where patients receive care and which treatments they receive, with implications for performance and equity in healthcare delivery (Zeltzer (2020); Agha et al. (2022)).\nPhysicians also exercise agency by influencing where patients receive care, including hospital choice and downstream referrals. In settings where patients rely on physician expertise to navigate complex provider choice sets, physician preferences and constraints can meaningfully affect hospital utilization. Evidence from institutional reforms that alter physician choice sets illustrates how agency interacts with market structure (Gaynor, Propper, and Seiler (2016)).\nFinally, agency is especially salient in settings where care is transferred or delegated across providers or facilities. These environments highlight how organizational rules and institutional incentives shape physician decision-making under tight constraints. Evidence from long-term acute care hospitals and emergency departments shows how agency affects utilization and patient outcomes in institutional settings (Eliason et al. (2018); Gruber, Hoe, and Stoye (2023)).\nTaken together, these papers show that physician agency cannot be understood solely at the individual level. Organizational structure and team-based decision-making are central to how care is delivered and how policy interventions ultimately operate. Potential papers for presentation today include:\n\nAgha et al. (2022) — referral networks and team structure\nGaynor, Propper, and Seiler (2016) — physician influence on hospital choice\nEliason et al. (2018) — agency in institutional care settings\n\n\n\n\n\nReferences\n\nAgha, Leila, Keith Marzilli Ericson, Kimberley H. Geissler, and James B. Rebitzer. 2022. “Team Relationships and Performance: Evidence from Healthcare Referral Networks.” Management Science 68 (5): 3735–54. https://doi.org/10.1287/mnsc.2021.4091.\n\n\nEliason, Paul J., Paul L. E. Grieco, Ryan C. McDevitt, and James W. Roberts. 2018. “Strategic Patient Discharge: The Case of Long-Term Care Hospitals.” American Economic Review 108 (11): 3232–65. https://doi.org/10.1257/aer.20170092.\n\n\nGaynor, Martin, Carol Propper, and Stephan Seiler. 2016. “Free to Choose? Reform, Choice, and Consideration Sets in the English National Health Service.” American Economic Review 106 (11): 3521–57. https://doi.org/10.1257/aer.20121532.\n\n\nGruber, Jonathan, Thomas P. Hoe, and George Stoye. 2023. “Saving Lives by Tying Hands: The Unexpected Effects of Constraining Health Care Providers.” The Review of Economics and Statistics 105 (1): 1–19. https://doi.org/10.1162/rest_a_01044.\n\n\nZeltzer, Dan. 2020. “Gender Homophily in Referral Networks: Consequences for the Medicare Physician Earnings Gap.” American Economic Journal: Applied Economics 12 (2): 169–97. https://doi.org/10.1257/app.20180201."
  },
  {
    "objectID": "schedule/2-1.html",
    "href": "schedule/2-1.html",
    "title": "Agency and Financial Incentives",
    "section": "",
    "text": "Today we focus on the role of financial incentives in the context of physician agency problems. This literature examines whether and how physicians respond to changes in payment when making treatment decisions. Financial incentives are a natural starting point for studying agency because they provide clear, measurable variation in the marginal returns to different clinical actions. At the same time, isolating causal effects is challenging, as payment changes often coincide with broader policy reforms or shifts in patient composition.\nEarly and influential work exploits settings in which physicians directly profit from specific treatment choices. For example, Iizuka (2012) studies prescribing behavior in Japan, where physicians both prescribe and dispense drugs, creating sharp financial incentives to favor branded pharmaceuticals over generics. The paper provides clean evidence that physicians respond to these incentives, highlighting how agency can distort treatment choices even in the absence of explicit patient demand.\nMore recent work leverages quasi-experimental variation in reimbursement rates to study physician responses in the U.S. healthcare system. Clemens and Gottlieb (2014) exploits plausibly exogenous changes in Medicare physician fees to estimate supply responses, showing that physicians adjust both the volume and intensity of care in response to payment changes. Importantly, the paper also examines downstream effects on patient health, illustrating how financial incentives can influence not only utilization but outcomes.\nTogether, these studies demonstrate that physicians respond to financial incentives in systematic ways, but also raise broader questions about the effectiveness and limits of payment-based policy tools. These questions motivate later discussions of non-financial incentives and organizational constraints.\nPotential papers for presentation today include:\n\nIizuka (2012) — physician dispensing incentives and prescribing behavior\nClemens and Gottlieb (2014) — reimbursement changes and physician treatment responses\nHo and Pakes (2014) — financial incentives, hospital choice, and physician behavior\n\n\n\n\n\nReferences\n\nClemens, Jeffrey, and Joshua D Gottlieb. 2014. “Do Physicians’ Financial Incentives Affect Medical Treatment and Patient Health?” American Economic Review 104 (4): 1320–49.\n\n\nHo, Kate, and Ariel Pakes. 2014. “Hospital Choices, Hospital Prices, and Financial Incentives to Physicians.” The American Economic Review 104 (12): 3841–84.\n\n\nIizuka, Toshiaki. 2012. “Physician Agency and Adoption of Generic Pharmaceuticals.” American Economic Review 102 (6): 2826–58."
  },
  {
    "objectID": "schedule/2-0.html",
    "href": "schedule/2-0.html",
    "title": "Physician Agency",
    "section": "",
    "text": "A central empirical fact motivating the study of physician agency is the substantial variation in healthcare utilization and spending across geographic areas and providers. Early work documenting small-area variation showed that patients with similar observable characteristics receive markedly different levels and types of care depending on where they live and which physicians they see (J. Wennberg and Gittelsohn (1973); J. E. Wennberg, Fisher, and Skinner (2004)). While some of this variation reflects differences in patient health and preferences, a large literature demonstrates that supply-side factors play an important role, raising questions about how treatment decisions are made in environments characterized by asymmetric information and physician discretion.\nPhysician agency provides a unifying framework for understanding these patterns. Physicians act as agents for patients, but they typically have discretion over diagnostic and treatment choices and face incentives that may not be perfectly aligned with patient welfare. Classic conceptual work formalizes this agency problem and emphasizes how physician objectives, information, and institutional constraints shape care delivery (McGuire (2000)). More recent empirical research builds on this framework to quantify the extent to which physicians contribute to observed variation in healthcare use, often exploiting patient or physician mobility to separate demand-side factors from physician practice styles (Finkelstein, Gentzkow, and Williams (2016); Badinski et al. (2023)).\nTogether, this body of work highlights physician agency as a key mechanism linking institutional features of healthcare markets to real differences in treatment intensity and patient outcomes. It also provides a foundation for subsequent discussions of how financial and non-financial incentives, as well as organizational structure, shape physician behavior.\nPotential papers for presentation today include:\n\nFinkelstein, Gentzkow, and Williams (2016) — separating demand- and supply-side sources of healthcare variation\nBadinski et al. (2023) — the role of physicians in explaining geographic variation in utilization\n\n\n\n\n\nReferences\n\nBadinski, Ivan, Amy Finkelstein, Matthew Gentzkow, and Peter Hull. 2023. “Geographic Variation in Healthcare Utilization: The Role of Physicians.” Working {Paper}. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w31749.\n\n\nFinkelstein, Amy, Matthew Gentzkow, and Heidi Williams. 2016. “Sources of Geographic Variation in Health Care: Evidence From Patient Migration.” The Quarterly Journal of Economics 131 (4): 1681–1726. https://ideas.repec.org//a/oup/qjecon/v131y2016i4p1681-1726..html.\n\n\nMcGuire, Thomas G. 2000. “Physician Agency.” Handbook of Health Economics 1: 461–536.\n\n\nWennberg, John E., Elliott S. Fisher, and Jonathan S. Skinner. 2004. “Geography And The Debate Over Medicare Reform.” Health Affairs, W96–114. https://www.proquest.com/docview/204500754/abstract/1F1C6E2B7FD14576PQ/1.\n\n\nWennberg, John, and Alan Gittelsohn. 1973. “Small Area Variations in Health Care Delivery: A Population-Based Health Information System Can Guide Planning and Regulatory Decision-Making.” Science 182 (4117): 1102–8."
  },
  {
    "objectID": "schedule/2-2.html",
    "href": "schedule/2-2.html",
    "title": "Agency and Non-financial Incentives",
    "section": "",
    "text": "While financial incentives operate through explicit changes in physician reimbursement, many important sources of physician agency arise from incentives that do not directly affect pay. In this class, we use non-financial incentives to refer to forces that shape physician behavior through professional norms, reputation, peer interactions, information, and institutional constraints, rather than through marginal payments for specific services. These incentives matter even when prices are held fixed and help explain why physicians facing similar financial environments may practice very differently. For example, physicians may internalize local standards of care, respond to peer behavior, or adjust treatment choices to avoid malpractice risk. Empirical work documents persistent physician-specific practice styles that affect both utilization and patient outcomes, even after controlling for patient characteristics and observable incentives (Currie, MacLeod, and Van Parys (2016); Molitor (2018)). These findings highlight that agency is not simply a response to prices, but also reflects learned behavior and social context.\nOther work emphasizes how informational frictions and expertise shape decision-making. Physicians often act as experts guiding patient choices, which can generate agency problems even in the absence of direct financial gain. For instance, referral decisions and diagnostic intensity may reflect physician beliefs, habits, or perceived responsibility rather than reimbursement alone. Studies exploiting variation in referral networks and physician mobility show that these non-financial channels can generate substantial differences in care delivery (Epstein and Nicholson (2009); Zeltzer (2020)).\nTogether, this literature demonstrates that non-financial incentives are central to understanding physician agency. These mechanisms complement—but are distinct from—financial incentives, and they motivate a broader view of physician behavior that incorporates norms, information, and social interactions. Potential papers for presentation today include:\n\nCurrie, MacLeod, and Van Parys (2016) — physician practice styles and patient health outcomes\nMolitor (2018) — evolution of physician behavior through migration\nZeltzer (2020) — referral networks, homophily, and physician behavior\n\n\n\n\n\nReferences\n\nCurrie, Janet, W. Bentley MacLeod, and Jessica Van Parys. 2016. “Provider Practice Style and Patient Health Outcomes: The Case of Heart Attacks.” Journal of Health Economics 47 (May): 64–80. https://doi.org/10.1016/j.jhealeco.2016.01.013.\n\n\nEpstein, Andrew J., and Sean Nicholson. 2009. “The Formation and Evolution of Physician Treatment Styles: An Application to Cesarean Sections.” Journal of Health Economics 28 (6): 1126–40. https://doi.org/10.1016/j.jhealeco.2009.08.003.\n\n\nMolitor, David. 2018. “The Evolution of Physician Practice Styles: Evidence from Cardiologist Migration.” American Economic Journal: Economic Policy 10 (1): 326–56.\n\n\nZeltzer, Dan. 2020. “Gender Homophily in Referral Networks: Consequences for the Medicare Physician Earnings Gap.” American Economic Journal: Applied Economics 12 (2): 169–97. https://doi.org/10.1257/app.20180201."
  },
  {
    "objectID": "schedule/5-literature.html",
    "href": "schedule/5-literature.html",
    "title": "Information Disclosure",
    "section": "",
    "text": "Module 5 considers information disclosure as a central policy and market-design tool in healthcare. The papers (listed in the drop-down below) examine how disclosing information about quality, prices, or performance affects behavior by patients, providers, insurers, and regulators. A recurring theme is that disclosure operates through multiple channels—consumer choice, provider incentives, learning, and strategic response—and its effects depend critically on what information is disclosed, to whom, and in what market environment. The readings span foundational theoretical and empirical work on report cards and ratings, as well as more recent evidence on insurance ratings and price transparency, highlighting both intended and unintended consequences of transparency policies.\n\n    List of Key Papers (click to expand)"
  },
  {
    "objectID": "schedule/3-literature.html",
    "href": "schedule/3-literature.html",
    "title": "Physician Learning",
    "section": "",
    "text": "Module 3 covers physician learning. More specifically, we study how physicians learn from experience, information, and peers, and how that learning shapes treatment choices and the adoption of new medical technologies. The readings span foundational models of learning under uncertainty, empirical evidence on learning-by-doing and skill accumulation, and work on learning about patient–treatment matches. The module also highlights the role of social learning and peer effects in the diffusion and abandonment of technologies. Together, these papers emphasize learning as a central mechanism driving heterogeneity in physician behavior, treatment patterns, and productivity, complementing the static incentive-based frameworks introduced earlier in the course.\n\n    List of Key Papers (click to expand)"
  },
  {
    "objectID": "schedule/5-1.html",
    "href": "schedule/5-1.html",
    "title": "Physician Quality",
    "section": "",
    "text": "A longstanding challenge in healthcare markets is that provider quality is difficult for patients to observe prior to receiving care. Public reporting of physician outcomes and quality measures is intended to address this information problem by helping patients make better choices and by creating incentives for providers to improve performance. Understanding the effects of physician quality disclosure therefore requires examining both how patients respond to quality information and how providers adjust their behavior in response to increased observability.\nThe literature on physician quality disclosure emphasizes two key margins of adjustment. First, public reporting can shift patient demand and referral patterns toward higher-rated providers, potentially improving allocative efficiency. Second, disclosure can induce changes in provider behavior through reputational concerns, intrinsic motivation, or strategic responses such as selection and gaming. Importantly, these effects need not align, and quality disclosure may improve measured performance without improving underlying care.\nWe introduce this literature by focusing on empirical work that isolates the causal effects of physician quality reporting on patient choice and provider behavior. These studies highlight both the promise of disclosure as a policy tool and the challenges it poses for measurement and welfare analysis. This discussion sets up the following classes on insurance ratings and price transparency, where similar mechanisms operate in different institutional contexts.\nPotential papers for presentation today include:\n\nDranove et al. (2003) — a foundational study of how public report cards affect provider behavior and outcomes\nKolstad (2013) — evidence on physician responses to quality disclosure driven by intrinsic motivation\nEpstein (2010) — analysis of how quality report cards reshape referral patterns among physicians\n\n\n\n\n\nReferences\n\nDranove, David, Daniel Kessler, Mark McClellan, and Mark Satterthwaite. 2003. “Is More Information Better? The Effects of Report Cards on Health Care Providers.” Journal of Political Economy 111 (3): 555–88.\n\n\nEpstein, Andrew J. 2010. “Effects of Report Cards on Referral Patterns to Cardiac Surgeons.” Journal of Health Economics 29 (5): 718–31. https://doi.org/10.1016/j.jhealeco.2010.06.002.\n\n\nKolstad, Jonathan T. 2013. “Information and Quality When Motivation Is Intrinsic: Evidence from Surgeon Report Cards.” American Economic Review 103 (7): 2875–2910."
  },
  {
    "objectID": "schedule/4-4.html",
    "href": "schedule/4-4.html",
    "title": "Vertical Integration",
    "section": "",
    "text": "Competition in healthcare is often discussed in horizontal terms, but vertical integration between providers and across levels of the healthcare supply chain has become increasingly prevalent. Hospitals have expanded their ownership of physician practices, insurers have acquired provider organizations, and health systems have adopted integrated delivery models that combine financing and care provision. These arrangements can alter incentives, information flows, and bargaining relationships in ways that standard horizontal competition frameworks do not capture.\nThe literature on vertical integration in healthcare examines whether these organizational changes primarily generate efficiency gains—such as improved care coordination, better information sharing, and reduced transaction costs—or instead increase market power through foreclosure, higher negotiated prices, or changes in referral patterns. Empirical studies document that vertical integration can affect prices, utilization, and spending, but the mechanisms remain an active area of debate. In contrast to horizontal mergers, the competitive effects of vertical integration often depend on subtle institutional details, including referral incentives, billing rules, and contractual restrictions.\nWe introduce this literature by focusing on recent empirical work that studies hospital–physician and insurer–provider integration using quasi-experimental designs. These papers highlight how vertical integration reshapes competitive dynamics without necessarily changing traditional concentration measures, and they underscore the importance of organizational form for understanding pricing and welfare in healthcare markets.\nPotential papers for presentation today include:\n\nCuesta, Noton, and Vatter (2019) — evidence on hospital–physician integration and spending\nKoch and Ulrick (2021) — vertical integration, referrals, and provider behavior\nCapps, Dranove, and Ody (2018) — foreclosure and price effects of vertical integration\n\n\n\n\n\nReferences\n\nCapps, Cory, David Dranove, and Christopher Ody. 2018. “The Effect of Hospital Acquisitions of Physician Practices on Prices and Spending.” Journal of Health Economics 59: 139–52.\n\n\nCuesta, José Ignacio, Carlos Noton, and Benjamin Vatter. 2019. “Vertical Integration Between Hospitals and Insurers.” {SSRN} {Scholarly} {Paper}. Rochester, NY. https://doi.org/10.2139/ssrn.3309218.\n\n\nKoch, Thomas, and Shawn W. Ulrick. 2021. “Price Effects of a Merger: Evidence from a Physicians’ Market.” Economic Inquiry 59 (2): 790–802. https://doi.org/10.1111/ecin.12954."
  },
  {
    "objectID": "schedule/4-2.html",
    "href": "schedule/4-2.html",
    "title": "Bargaining and Hospital Pricing",
    "section": "",
    "text": "While reduced-form merger studies provide compelling evidence that consolidation raises hospital prices, they are less informative about the mechanisms through which prices are set and how alternative market structures would affect outcomes. To address these questions, a large literature models hospital prices as the outcome of bilateral bargaining between hospitals and insurers. In these models, negotiated prices depend on the relative bargaining power of each side, the value of inclusion in insurer networks, and the availability of alternative providers and plans.\nThe bargaining framework provides a structural interpretation of hospital pricing that links market structure, network design, and prices in a unified way. By explicitly modeling negotiations, these approaches allow researchers to simulate counterfactual scenarios—such as mergers that have not occurred, changes in network inclusion, or regulatory interventions—and to decompose price effects into changes in bargaining leverage versus underlying costs or demand. This makes bargaining models particularly attractive for policy analysis, despite their stronger assumptions relative to reduced-form designs.\nWe introduce this literature by focusing on empirical models that estimate negotiated prices and bargaining parameters using detailed claims and network data. These papers illustrate how bargaining power varies across hospitals and insurers, how market concentration affects negotiated outcomes, and how structural models complement reduced-form evidence from merger retrospectives. Together, they provide the analytical foundation for understanding hospital pricing in modern healthcare markets.\nPotential papers for presentation today include:\n\nGowrisankaran, Nevo, and Town (2015) — a canonical model of insurer–hospital bargaining and negotiated prices\nLewis and Pflum (2015) — evidence on bargaining power and system-level pricing effects\nHo and Lee (2017) — integration of bargaining models with insurance market structure\n\n\n\n\n\nReferences\n\nGowrisankaran, Gautam, Aviv Nevo, and Robert Town. 2015. “Mergers When Prices Are Negotiated: Evidence from the Hospital Industry.” American Economic Review 105 (1): 172–203.\n\n\nHo, Kate, and Robin S Lee. 2017. “Insurer Competition in Health Care Markets.” Econometrica 85 (2): 379–417.\n\n\nLewis, Matthew, and Kevin Pflum. 2015. “Diagnosing Hospital System Bargaining Power in Managed Care Networks.” American Economic Journal: Economic Policy 7 (1): 243–74."
  },
  {
    "objectID": "schedule/4-0.html",
    "href": "schedule/4-0.html",
    "title": "Understanding Hospital Competition",
    "section": "",
    "text": "A central challenge in studying hospital pricing is that competition in healthcare operates very differently than in standard goods markets. Hospitals provide highly differentiated services, patients are largely insulated from prices at the point of care, and prices are determined through bilateral negotiations between hospitals and insurers rather than posted prices. Physician referral patterns, insurer network design, and regulatory constraints further complicate how demand responds to prices and how market power is exercised. As a result, familiar notions of competition and marginal-cost pricing must be adapted to fit the institutional realities of hospital markets.\nThe literature on hospital competition develops frameworks for understanding how these institutional features shape prices, quality, and welfare. Rather than focusing solely on patient choice, this work emphasizes bargaining between hospitals and insurers, the role of outside options created by network inclusion, and the importance of market definition in differentiated product markets. Early contributions established that hospital market structure is closely linked to prices and outcomes, while later work refined empirical strategies and theoretical models to better capture negotiated pricing and strategic interaction.\nWe introduce this literature by drawing on survey and review papers that synthesize the key mechanisms underlying hospital competition and market power. These readings clarify why consolidation has the potential to raise prices even in nonprofit settings, why standard concentration measures can be misleading, and how institutional details matter for both empirical measurement and policy analysis. This foundation provides the context for the next classes, which examine reduced-form evidence on hospital mergers and structural models of insurer–hospital bargaining.\nPotential papers for presentation today include:\n\nDranove and Satterthwaite (2000) — a foundational overview of competition and market power in healthcare markets\nMartin Gaynor and Vogt (2003) — early conceptual and empirical analysis of hospital competition\nM. Gaynor, Ho, and Town (2015) — a comprehensive synthesis of theory and evidence on hospital competition and pricing\n\n\n\n\n\nReferences\n\nDranove, David, and Mark A Satterthwaite. 2000. “The Industrial Organization of Health Care Markets.” Handbook of Health Economics 1: 1093–1139.\n\n\nGaynor, Martin, and William B Vogt. 2003. “Competition Among Hospitals.” RAND Journal of Economics, 764–85.\n\n\nGaynor, M, K Ho, and R Town. 2015. “The Industrial Organization of Health Care Markets.” Journal of Economic Literature 47 (2): 235–84."
  },
  {
    "objectID": "schedule/3-2.html",
    "href": "schedule/3-2.html",
    "title": "Patient-Treatment Match Value",
    "section": "",
    "text": "An important source of physician learning arises from heterogeneity in patient responses to treatment. Even when average treatment effects are well understood, physicians often face uncertainty about how particular patients will respond, creating scope for learning about patient–treatment match quality. This form of learning is central to personalized medicine and provides a dynamic explanation for variation in treatment patterns across physicians and over time.\nThe literature on learning about match value emphasizes that physicians update beliefs not only about treatments in general, but about how treatments perform for different types of patients. Learning therefore depends on diagnostic signals, observed outcomes, and the physician’s willingness to experiment across patient populations. Early structural work in pharmaceutical markets formalizes this idea by modeling how learning about heterogeneous treatment effects shapes prescribing behavior following new drug entry (Coscelli and Shum (2004); Crawford and Shum (2005)). These models show that uncertainty about match quality can generate gradual diffusion, persistence in prescribing, and patient-level sorting across treatments.\nMore recent work brings these ideas directly into clinical settings, highlighting the role of diagnostic skill and information in guiding experimentation. (currie2020?) develops a model in which physicians learn about both treatment effectiveness and patient-specific match quality, showing how higher diagnostic skill leads to better targeting of therapies and improved patient outcomes. Together, this literature frames learning about match value as a key mechanism linking uncertainty, experimentation, and heterogeneity in care, distinct from both learning-by-doing and social learning.\nPotential papers for presentation today include:\n\nCoscelli and Shum (2004) — learning about heterogeneous treatment effects with patient spillovers\nCrawford and Shum (2005) — dynamic learning and matching in pharmaceutical demand\n(currie2020?) — physician learning, diagnostic skill, and treatment matching\n\n\n\n\n\nReferences\n\nCoscelli, Andrea, and Matthew Shum. 2004. “An Empirical Model of Learning and Patient Spillovers in New Drug Entry.” Journal of Econometrics 122 (2): 213–46. https://doi.org/10.1016/j.jeconom.2003.09.002.\n\n\nCrawford, Gregory S, and Matthew Shum. 2005. “Uncertainty and Learning in Pharmaceutical Demand.” Econometrica 73 (4): 1137–73."
  },
  {
    "objectID": "schedule/3-0.html",
    "href": "schedule/3-0.html",
    "title": "Learning Under Uncertainty",
    "section": "",
    "text": "An important feature of medical decision-making is that physicians often operate under substantial uncertainty about treatment effectiveness, side effects, and patient-specific responses. Much of clinical knowledge is acquired outside of formal training, through experience, feedback from outcomes, and exposure to new information. As a result, treatment decisions reflect not only preferences and incentives, but also evolving beliefs shaped by incomplete and noisy signals.\nThe literature on physician learning provides a framework for understanding how doctors update beliefs over time and how uncertainty influences treatment choice. Learning models formalize the idea that physicians face trade-offs between exploiting treatments they believe to be effective and experimenting with alternatives to gain information. These dynamics can generate persistence in practice styles, delayed adoption of new technologies, and heterogeneity in care even among observationally similar physicians.\nWe introduce this literature using Ching, Erdem, and Keane (2013), which reviews the development of empirical learning models in consumer and physician behavior over the past two decades. Building on foundational work such as Erdem and Keane (1996), the paper highlights how dynamic learning models have improved our understanding of decision-making under uncertainty, while also emphasizing key empirical challenges. In particular, it discusses the difficulty of distinguishing learning from other sources of persistence, such as habit formation or switching costs, and the importance of directly measuring information, beliefs, and expectations. This framework provides a common language for the remainder of the module, where we examine specific objects of learning and their implications for treatment decisions and technology adoption.\nPotential papers for presentation today include:\n\nChing, Erdem, and Keane (2013) — a synthesis of learning models and their empirical challenges\nErdem and Keane (1996) — a canonical framework for dynamic decision-making under uncertainty\nChan, Narasimhan, and Xie (2013) — a physician-focused model of learning about treatment effectiveness and side effects\n\n\n\n\n\nReferences\n\nChan, Tat, Chakravarthi Narasimhan, and Ying Xie. 2013. “Treatment Effectiveness and Side Effects: A Model of Physician Learning.” Management Science 59 (6): 1309–25.\n\n\nChing, Andrew T., Tülin Erdem, and Michael P. Keane. 2013. “Learning Models: An Assessment of Progress, Challenges, and New Developments.” Marketing Science 32 (6): 913–38. https://doi.org/10.1287/mksc.2013.0805.\n\n\nErdem, Tülin, and Michael P. Keane. 1996. “Decision-Making Under Uncertainty: Capturing Dynamic Brand Choice Processes in Turbulent Consumer Goods Markets.” Marketing Science 15 (1): 1–20. https://www.jstor.org/stable/184181."
  },
  {
    "objectID": "schedule/3-1.html",
    "href": "schedule/3-1.html",
    "title": "Skill Accumulation and Learning by Doing",
    "section": "",
    "text": "A distinct form of physician learning occurs through learning by doing, whereby repeated practice improves clinical skill and decision quality over time. Unlike belief updating about treatment effectiveness, skill accumulation reflects changes in a physician’s underlying productivity or ability, often tied to procedural volume and experience. This mechanism has been used to explain persistent differences in outcomes across physicians and hospitals, as well as the concentration of complex procedures among high-volume providers.\nThe literature on skill accumulation emphasizes that experience can affect both treatment choices and patient outcomes. Early empirical work documents strong volume–outcome relationships and productivity spillovers, suggesting that experience generates improvements that extend beyond the individual patient encounter (Chandra and Staiger (2007)). More recent work embeds learning-by-doing directly into dynamic models of physician behavior, allowing experience to interact with experimentation and patient selection. For example, Gong (2018) develops a structural model in which physicians simultaneously learn about treatment effectiveness and accumulate procedural skill, showing how these forces jointly shape treatment decisions and technology diffusion.\nAn important insight from this literature is that experience does not always lead to efficient learning. Skill accumulation may be distorted by biased beliefs or imperfect feedback, particularly when physicians misperceive their own ability. Comin, Skinner, and Staiger (2022) highlights how overconfidence in perceived skill can drive excessive adoption of new technologies, and how learning about this bias over time can generate both rapid diffusion and subsequent abandonment. Together, these papers underscore that learning by doing is a powerful but imperfect mechanism, with implications for productivity, technology adoption, and patient outcomes.\nPotential papers for presentation today include:\n\nChandra and Staiger (2007) — productivity spillovers and learning by doing in acute care\nGong (2018) — joint learning by doing and Bayesian updating in treatment choice\nComin, Skinner, and Staiger (2022) — skill misperception, learning, and technology adoption\n\n\n\n\n\nReferences\n\nChandra, Amitabh, and Douglas O. Staiger. 2007. “PRODUCTIVITY SPILLOVERS IN HEALTHCARE: EVIDENCE FROM THE TREATMENT OF HEART ATTACKS.” The Journal of Political Economy 115: 103–40. https://doi.org/10.1086/512249.\n\n\nComin, Diego A., Jonathan S. Skinner, and Douglas O. Staiger. 2022. “Overconfidence and Technology Adoption in Health Care.” Working {Paper}. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w30345.\n\n\nGong, Qing. 2018. “Physician Learning and Treatment Choices Evidence from Brain Aneurysms.” Working {Paper}. University of North Carolina at Chapel Hill."
  },
  {
    "objectID": "schedule/3-3.html",
    "href": "schedule/3-3.html",
    "title": "Learning from Others",
    "section": "",
    "text": "Physicians rarely learn in isolation. In addition to updating beliefs based on their own experience, doctors observe and respond to the behavior, outcomes, and information generated by others. This social learning can occur through informal peer interactions, professional networks, exposure to new clinical evidence, or high-profile early adopters. As a result, learning from others plays a central role in the diffusion—and sometimes abandonment—of medical practices and technologies.\nThe literature on social learning emphasizes that information flows across physicians can generate spillovers that amplify or dampen individual learning. Early empirical work shows that physician productivity and treatment choices respond to the experience and outcomes of nearby peers, even in the absence of direct coordination or shared incentives (Chandra and Staiger (2007)). Related work highlights the role of “pioneer” physicians and opinion leaders in shaping local adoption patterns, particularly when new technologies or drugs enter the market (Agha and Molitor (2018)). These studies demonstrate how social learning can generate clustered adoption, path dependence, and persistent regional variation in care.\nMore recent research expands the notion of learning from others to include formal sources of information, such as clinical guidelines, research trials, and performance feedback. (dubois2021?) shows how scientific information and recommendations influence prescribing behavior, while also documenting heterogeneity in physician responses. Together, this body of work underscores that learning from others is neither frictionless nor uniform: physicians differ in whom they observe, how they interpret signals, and how social information interacts with their own experience. This perspective provides a natural bridge to subsequent discussions of organizational structure and market forces in healthcare.\nPotential papers for presentation today include:\n\nChandra and Staiger (2007) — peer spillovers and productivity in medical practice\nAgha and Molitor (2018) — the role of pioneer investigators in technology adoption\n(dubois2021?) — physician responses to scientific information and recommendations\n\n\n\n\n\nReferences\n\nAgha, Leila, and David Molitor. 2018. “The Local Influence of Pioneer Investigators on Technology Adoption: Evidence from New Cancer Drugs.” The Review of Economics and Statistics 100 (1): 29–44. https://doi.org/10.1162/REST_a_00670.\n\n\nChandra, Amitabh, and Douglas O. Staiger. 2007. “PRODUCTIVITY SPILLOVERS IN HEALTHCARE: EVIDENCE FROM THE TREATMENT OF HEART ATTACKS.” The Journal of Political Economy 115: 103–40. https://doi.org/10.1086/512249."
  },
  {
    "objectID": "schedule/4-1.html",
    "href": "schedule/4-1.html",
    "title": "Competition in Reduced Form",
    "section": "",
    "text": "A central empirical challenge in studying hospital competition is identifying the causal effect of market structure on prices and outcomes. Early empirical work often relied on cross-sectional correlations between measures of concentration and prices, but concerns about endogeneity and market definition have motivated a shift toward research designs that exploit discrete changes in competitiveness. In hospital markets, mergers, closures, and entry events provide natural settings in which competitive conditions change sharply, allowing researchers to study how prices and quality respond.\nThe reduced-form literature on hospital mergers uses quasi-experimental designs to estimate the effects of consolidation without fully specifying the underlying pricing or bargaining process. These studies typically compare prices or outcomes in markets affected by mergers to those in unaffected markets, using difference-in-differences or event-study approaches. A central finding of this literature is that hospital mergers lead to large and persistent price increases, even in settings with nonprofit ownership and regulated payment systems. This evidence plays a prominent role in antitrust enforcement because it relies on transparent identification strategies and minimal structural assumptions.\nIn addition to prices, a smaller but important literature studies how consolidation affects hospital quality. Measuring quality responses is empirically challenging, both because quality is multidimensional and because improvements in care coordination may offset reductions in competitive pressure. Existing evidence suggests that quality effects are heterogeneous and often muted relative to price effects, with some studies finding no improvement—and in some cases deterioration—in clinical outcomes following consolidation. These results highlight an important asymmetry in merger effects and reinforce the policy relevance of price-based evidence.\nTogether, these papers motivate the need for richer models of hospital pricing and incentives, which we take up in the next class on insurer–hospital bargaining. Potential papers for presentation today include:\n\nKessler and McClellan (2000) — competition, prices, and quality in hospital markets\nDafny (2009) — design-based evidence on hospital mergers and price effects\nGaynor, Moreno-Serra, and Propper (2013) — evidence on hospital competition and patient outcomes\n\n\n\n\n\nReferences\n\nDafny, Leemore. 2009. “Estimation and Identification of Merger Effects: An Application to Hospital Mergers.” Journal of Law and Economics 52 (3): 523–50.\n\n\nGaynor, Martin, Rodrigo Moreno-Serra, and Carol Propper. 2013. “Death by Market Power: Reform, Competition, and Patient Outcomes in the National Health Service.” American Economic Journal: Economic Policy 5 (4): 134–66.\n\n\nKessler, Daniel, and Mark McClellan. 2000. “Is Hospital Competition Socially Wasteful?” Quarterly Journal of Economics 2 (115): 577–615."
  },
  {
    "objectID": "schedule/4-3.html",
    "href": "schedule/4-3.html",
    "title": "Cross-Market Mergers",
    "section": "",
    "text": "Much of the literature on hospital consolidation focuses on mergers between hospitals that compete in the same geographic market. However, a growing share of hospital mergers involve systems that operate in distinct local markets and do not directly compete for patients. These cross-market mergers pose a challenge for standard antitrust analysis, since they do not mechanically reduce local competition or increase concentration as measured by traditional market-definition tools. Understanding how such mergers affect prices therefore requires alternative economic mechanisms.\nRecent work emphasizes that cross-market consolidation can increase prices through changes in bargaining leverage rather than local market power. When a hospital system operates in multiple markets, it may gain the ability to negotiate higher prices by leveraging common insurers or employers across markets, even if hospitals within a given market remain geographically distinct. Related work draws on the concept of multimarket contact, in which firms competing across multiple markets internalize the effects of aggressive pricing in one market on competition in others. These mechanisms suggest that consolidation can raise prices even in the absence of within-market overlap.\nWe introduce this literature by focusing on empirical studies that test these mechanisms in hospital markets. These papers examine how prices respond to system expansion across markets and how shared customers and multimarket interactions shape bargaining outcomes. Together, they extend the standard merger framework and highlight the importance of system-level organization for understanding hospital pricing.\nPotential papers for presentation today include:\n\nDafny, Ho, and Lee (2019) — evidence on cross-market mergers and the common-customer mechanism\nSchmitt (2018) — multimarket contact and hospital pricing\nLewis and Pflum (2017) — system expansion and bargaining leverage across markets\n\n\n\n\n\nReferences\n\nDafny, Leemore, Kate Ho, and Robin S Lee. 2019. “The Price Effects of Cross-Market Mergers: Theory and Evidence from the Hospital Industry.” RAND Journal of Economics 50 (2): 286–325.\n\n\nLewis, Matthew S, and Kevin E Pflum. 2017. “Hospital Systems and Bargaining Power: Evidence from Out-of-Market Acquisitions.” The RAND Journal of Economics 48 (3): 579–610.\n\n\nSchmitt, Matt. 2018. “Multimarket Contact in the Hospital Industry.” American Economic Journal: Economic Policy 10 (3): 361–87."
  },
  {
    "objectID": "schedule/5-0.html",
    "href": "schedule/5-0.html",
    "title": "Basics of Information Disclosure",
    "section": "",
    "text": "A defining feature of healthcare markets is that key dimensions of quality, prices, and performance are often difficult for patients, providers, and payers to observe. These information frictions motivate a wide range of disclosure policies, including public reporting of provider quality, insurance plan ratings, and posted prices. Understanding how disclosure affects behavior requires careful attention to who receives the information, what exactly is disclosed, and how agents incorporate that information into their decisions.\nThe literature on information disclosure studies how increased observability changes market outcomes through several channels. On the demand side, disclosure can shift patient or enrollee choice by reducing uncertainty or correcting misperceptions. On the supply side, disclosure can alter provider incentives through reputation, referral patterns, and competitive pressure. At the same time, disclosure may induce strategic responses that complicate both empirical measurement and welfare analysis.\nWe introduce this literature by focusing on core economic mechanisms and general lessons that apply across institutional settings. This framework provides the foundation for the next classes on physician quality reporting, insurance ratings, and price transparency. Potential papers for presentation today include:\n\nDranove and Jin (2010) — a canonical survey of theory and evidence on quality disclosure and certification\nLuco (2019) — modern evidence on equilibrium and distributional effects of price disclosure\n\n\n\n\n\nReferences\n\nDranove, David, and Ginger Zhe Jin. 2010. “Quality Disclosure and Certification: Theory and Practice.” Journal of Economic Literature 48 (4): 935–63.\n\n\nLuco, Fernando. 2019. “Who Benefits from Information Disclosure? The Case of Retail Gasoline.” American Economic Journal: Microeconomics 11 (2): 277–305. https://doi.org/10.1257/mic.20170110."
  },
  {
    "objectID": "schedule/5-2.html",
    "href": "schedule/5-2.html",
    "title": "Insurance Ratings",
    "section": "",
    "text": "In insurance markets, consumers typically observe prices but face substantial uncertainty about plan quality, including network adequacy, customer service, and utilization management. Public ratings systems—such as Medicare Advantage star ratings—are designed to summarize these multidimensional quality attributes and guide consumer choice. Because these ratings are also tied to regulatory and financial incentives, they have the potential to shape both demand and insurer behavior.\nThe literature on insurance ratings studies how consumers respond to publicly reported plan quality and how insurers adjust plan design, marketing, and coding practices in response to rating thresholds. On the demand side, ratings can reallocate enrollment across plans, affecting market shares and competitive dynamics. On the supply side, ratings may induce strategic responses that improve measured performance without necessarily improving underlying quality. As a result, insurance ratings provide a useful setting for studying the interaction between information disclosure, incentives, and market design.\nWe introduce this literature by focusing on empirical work that identifies the causal effects of insurance ratings on enrollment and insurer behavior. These papers illustrate how disclosure can amplify or distort incentives when ratings are embedded in regulatory frameworks, and they provide a natural bridge to broader discussions of transparency and competition in health insurance markets.\nPotential papers for presentation today include:\n\nJin and Sorensen (2006) — a classic analysis of how publicized plan ratings affect consumer choice\nDarden and McCarthy (2015) — evidence on the impact of Medicare Advantage star ratings on enrollment\n\n\n\n\n\nReferences\n\nDarden, M., and I. McCarthy. 2015. “The Star Treatment: Estimating the Impact of Star Ratings on Medicare Advantage Enrollments.” Journal of Human Resources 50 (4): 980–1008.\n\n\nJin, G. Z., and A. T. Sorensen. 2006. “Information and Consumer Choice: The Value of Publicized Health Plan Ratings.” Journal of Health Economics 25 (2): 248–75."
  },
  {
    "objectID": "schedule/4-literature.html",
    "href": "schedule/4-literature.html",
    "title": "Hospital Competition and Pricing",
    "section": "",
    "text": "Module 4 examines competition and pricing in hospital markets. We study how market structure, bargaining relationships, and organizational form shape hospital prices, quality, and strategic behavior. The readings span foundational work on hospital market power and price determination, reduced-form evidence on the effects of hospital mergers, and structural models of insurer–hospital bargaining used to evaluate counterfactual market outcomes. The module also covers recent research on cross-market mergers and vertical integration, highlighting how system-level organization and ownership arrangements alter competitive incentives beyond local markets. Together, these papers emphasize the central role of market power and contracting institutions in shaping prices and welfare in healthcare markets, and provide a bridge between physician behavior and insurer–provider interactions later in the course. Below is a drop-down list of papers most relevant for this module.\n\n    List of Key Papers (click to expand)"
  },
  {
    "objectID": "schedule/5-3.html",
    "href": "schedule/5-3.html",
    "title": "Price Transparency",
    "section": "",
    "text": "Good catch — Grennan and Swanson (2020) absolutely belongs here, and it actually strengthens this day conceptually.\nThe key is to position it as price transparency in bargaining environments, not just posted-price transparency to consumers.\nHere’s the revised Day 4, with Grennan–Swanson integrated cleanly.\n\n---\ntitle: \"Price Transparency\"\n---\nUnlike most goods markets, prices in healthcare are typically determined through negotiation rather than posted prices, and are often opaque to patients, providers, and even market participants themselves. Recent policy efforts aimed at increasing price transparency seek to reduce this opacity by making prices observable, with the goal of promoting competition and lowering spending. Whether transparency achieves these goals depends critically on how price information enters bargaining, demand, and strategic interaction.\nThe literature on price transparency emphasizes that disclosure can have ambiguous effects in markets with imperfect competition. Transparency may shift patient demand or referral patterns, but it can also alter bargaining positions, outside options, and negotiated prices between firms. As a result, transparency can intensify competition in some settings while facilitating coordination or redistributing surplus in others. Understanding these effects requires attention to equilibrium responses and institutional detail.\nWe introduce this literature by focusing on empirical work that studies how price information affects outcomes in bargaining and competitive environments. These papers highlight when transparency improves efficiency and when it may instead change who captures surplus without lowering prices. This class concludes the module by emphasizing transparency as a mechanism that reshapes strategic interaction, rather than as a uniformly pro-competitive policy.\nPotential papers for presentation today include:\n\nGrennan and Swanson (2020) — a canonical analysis of how transparency affects negotiated prices and bargaining power\nChristensen, Floyd, and Maffett (2020) — evidence on price transparency regulation and healthcare prices\nBrown (2019) — equilibrium effects of healthcare price information\n\n\n\n\n\nReferences\n\nBrown, Zach Y. 2019. “Equilibrium Effects of Health Care Price Information.” The Review of Economics and Statistics 101 (4): 699–712. https://doi.org/10.1162/rest_a_00765.\n\n\nChristensen, Hans B., Eric Floyd, and Mark Maffett. 2020. “The Only Prescription Is Transparency: The Effect of Charge-Price-Transparency Regulation on Healthcare Prices.” Management Science 66 (7): 2861–82. https://doi.org/10.1287/mnsc.2019.3330.\n\n\nGrennan, Matthew, and Ashley Swanson. 2020. “Transparency and Negotiated Prices: The Value of Information in Hospital-Supplier Bargaining.” Journal of Political Economy 128 (4): 1234–68."
  },
  {
    "objectID": "assignments/presentations.html#module-1-insurance",
    "href": "assignments/presentations.html#module-1-insurance",
    "title": "Presentations",
    "section": "Module 1: Insurance",
    "text": "Module 1: Insurance\nAron-Dine, Einav, and Finkelstein (2013) Finkelstein et al. (2012) Brot-Goldberg et al. (2023) Hu et al. (2018) Miller, Johnson, and Wherry (2021) Finkelstein, Hendren, and Luttmer (2019) Einav, Finkelstein, and Cullen (2010) Handel, Kolstad, and Spinnewijn (2019) Shepard (2022) Dafny, Duggan, and Ramanarayanan (2012) Ho and Lee (2017) Cabral, Geruso, and Mahoney (2018) V. Curto et al. (2021) Layton et al. (2019) Geddes and Schnell (2023) V. E. Curto (2023)",
    "crumbs": [
      "Assignments",
      "Presentations"
    ]
  },
  {
    "objectID": "assignments/presentations.html#module-2-physician-agency",
    "href": "assignments/presentations.html#module-2-physician-agency",
    "title": "Presentations",
    "section": "Module 2: Physician Agency",
    "text": "Module 2: Physician Agency\nFinkelstein, Gentzkow, and Williams (2016) Badinski et al. (2023) J. Currie, MacLeod, and Van Parys (2016) Iizuka (2012) Clemens and Gottlieb (2014) Ho and Pakes (2014) Molitor (2018) Zeltzer (2020) Agha et al. (2022) Martin Gaynor, Propper, and Seiler (2016) Eliason et al. (2018) Gruber, Hoe, and Stoye (2023)",
    "crumbs": [
      "Assignments",
      "Presentations"
    ]
  },
  {
    "objectID": "assignments/presentations.html#module-3-learning",
    "href": "assignments/presentations.html#module-3-learning",
    "title": "Presentations",
    "section": "Module 3: Learning",
    "text": "Module 3: Learning\nChing, Erdem, and Keane (2013) Erdem and Keane (1996) Chan, Narasimhan, and Xie (2013) Chandra and Staiger (2007) Gong (2018) Comin, Skinner, and Staiger (2022) Coscelli and Shum (2004) Crawford and Shum (2005) J. M. Currie and MacLeod (2020) Agha and Molitor (2018) Dubois and Tuncel (2021) Dickstein (2018)",
    "crumbs": [
      "Assignments",
      "Presentations"
    ]
  },
  {
    "objectID": "assignments/presentations.html#module-4-competition",
    "href": "assignments/presentations.html#module-4-competition",
    "title": "Presentations",
    "section": "Module 4: Competition",
    "text": "Module 4: Competition\nDranove and Satterthwaite (2000) Martin Gaynor and Vogt (2003) M. Gaynor, Ho, and Town (2015) Kessler and McClellan (2000) Dafny (2009) Cooper et al. (2019) Martin Gaynor, Moreno-Serra, and Propper (2013) Gowrisankaran, Nevo, and Town (2015) M. Lewis and Pflum (2015) Ho and Lee (2017) Dafny, Ho, and Lee (2019) Schmitt (2018) M. S. Lewis and Pflum (2017) Cuesta, Noton, and Vatter (2019) Koch and Ulrick (2021) Capps, Dranove, and Ody (2018)",
    "crumbs": [
      "Assignments",
      "Presentations"
    ]
  },
  {
    "objectID": "assignments/presentations.html#module-5-disclosure",
    "href": "assignments/presentations.html#module-5-disclosure",
    "title": "Presentations",
    "section": "Module 5: Disclosure",
    "text": "Module 5: Disclosure\nDranove and Jin (2010) Luco (2019) Dranove et al. (2003) Kolstad (2013) Epstein (2010) Jin and Sorensen (2006) Darden and McCarthy (2015) Grennan and Swanson (2020) Christensen, Floyd, and Maffett (2020) Brown (2019)",
    "crumbs": [
      "Assignments",
      "Presentations"
    ]
  }
]